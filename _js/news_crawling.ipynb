{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml_html_clean\n",
      "  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: lxml in c:\\anaconda3\\lib\\site-packages (from lxml_html_clean) (5.2.1)\n",
      "Downloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: lxml_html_clean\n",
      "Successfully installed lxml_html_clean-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml_html_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newspaper3k\n",
      "  Using cached newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\anaconda3\\lib\\site-packages (from newspaper3k) (4.12.3)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\anaconda3\\lib\\site-packages (from newspaper3k) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=3.11 in c:\\anaconda3\\lib\\site-packages (from newspaper3k) (6.0.1)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in c:\\anaconda3\\lib\\site-packages (from newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\anaconda3\\lib\\site-packages (from newspaper3k) (5.2.1)\n",
      "Requirement already satisfied: nltk>=3.2.1 in c:\\anaconda3\\lib\\site-packages (from newspaper3k) (3.9.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\anaconda3\\lib\\site-packages (from newspaper3k) (2.32.3)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "  Using cached feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in c:\\anaconda3\\lib\\site-packages (from newspaper3k) (5.1.2)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Using cached feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Using cached jieba3k-0.35.1.zip (7.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\anaconda3\\lib\\site-packages (from newspaper3k) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Using cached tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.5)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
      "  Using cached sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: click in c:\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2025.6.15)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (3.13.1)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from click->nltk>=3.2.1->newspaper3k) (0.4.6)\n",
      "Using cached newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Using cached feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py): started\n",
      "  Building wheel for tinysegmenter (setup.py): finished with status 'done'\n",
      "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13566 sha256=ef1d2ced9a16565de4440893168ad7ba135915839193f362971fbea09dd0368b\n",
      "  Stored in directory: c:\\users\\neul\\appdata\\local\\pip\\cache\\wheels\\a5\\91\\9f\\00d66475960891a64867914273fcaf78df6cb04d905b104a2a\n",
      "  Building wheel for feedfinder2 (setup.py): started\n",
      "  Building wheel for feedfinder2 (setup.py): finished with status 'done'\n",
      "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3358 sha256=dd1096a08337d579ce986f9a967205d8fe05a01a69b7eb971f4c95b0d464475a\n",
      "  Stored in directory: c:\\users\\neul\\appdata\\local\\pip\\cache\\wheels\\9f\\9f\\fb\\364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\n",
      "  Building wheel for jieba3k (setup.py): started\n",
      "  Building wheel for jieba3k (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398386 sha256=4a8e253c648cca87e1ffc0d96287a521cdb8cd8113fa4154a082dc5d26ca6de9\n",
      "  Stored in directory: c:\\users\\neul\\appdata\\local\\pip\\cache\\wheels\\26\\72\\f7\\fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6060 sha256=1f55bbe780588c713217058c32da0a10b23aae776e3c505fdd5f5d7121e760bf\n",
      "  Stored in directory: c:\\users\\neul\\appdata\\local\\pip\\cache\\wheels\\03\\f5\\1a\\23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, feedfinder2, newspaper3k\n",
      "Successfully installed feedfinder2-0.0.4 feedparser-6.0.11 jieba3k-0.35.1 newspaper3k-0.2.8 sgmllib3k-1.0.0 tinysegmenter-0.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from newspaper import Article\n",
    "\n",
    "# 🔍 네이버 뉴스 검색\n",
    "def search_naver_news_all(query, target_dates):\n",
    "    headers = {\n",
    "        \"X-Naver-Client-Id\": NAVER_CLIENT_ID,\n",
    "        \"X-Naver-Client-Secret\": NAVER_CLIENT_SECRET\n",
    "    }\n",
    "    all_filtered = []\n",
    "    for start in range(1, 500, 100):\n",
    "        params = {\n",
    "            \"query\": query,\n",
    "            \"display\": 100,\n",
    "            \"start\": start,\n",
    "            \"sort\": \"sim\"\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(\"https://openapi.naver.com/v1/search/news.json\", headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "        except:\n",
    "            break\n",
    "        items = response.json().get(\"items\", [])\n",
    "        for item in items:\n",
    "            try:\n",
    "                pubdate = parsedate_to_datetime(item[\"pubDate\"]).date()\n",
    "                if pubdate in target_dates:\n",
    "                    all_filtered.append(item[\"originallink\"].replace(\"amp;\", \"\"))\n",
    "            except:\n",
    "                continue\n",
    "    return all_filtered\n",
    "\n",
    "# 📄 기사 본문 추출\n",
    "def extract_article_text(url):\n",
    "    try:\n",
    "        article = Article(url, language=\"ko\")\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.text\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "횡령 ·배임·뇌물 같은 혐의로 수사를 받는 재벌 총수나 정치인들이 검경의 소환 수사를 전후해 몸이 아프다는 ‘감성팔이’ 수법으로 악용하곤 했다. 세인의 뇌리에 오래 남아 있는 게 1997년 정태수 한보그룹 전 회장이다. 외환위기 도화선이 된 비자금과 정·관계 로비 의혹으로 국회 청문회에 출석할 때, 그는...\n"
     ]
    }
   ],
   "source": [
    "text = extract_article_text('https://search.naver.com/search.naver?ssc=tab.news.all&query=%ED%9A%A1%EB%A0%B9&sm=tab_opt&sort=0&photo=3&field=0&pd=3&ds=2019.06.30&de=2025.06.30&docid=&related=0&mynews=1&office_type=3&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom20190630to20250630&is_sug_officeid=0&office_category=1&service_area=0')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_news_from_webhook(query: str, date: str, news_office_checked: str) -> dict:\n",
    "    \"\"\"n8n을 통해 supabase에 뉴스를 저장하는 함수\n",
    "    \n",
    "    Args:\n",
    "        query (str): 검색어\n",
    "        date (str): 날짜 (YYYY.MM.DD 형식)\n",
    "        news_office_checked (str): 뉴스사 ID\n",
    "          1023(조선일보)\n",
    "          1025(중앙일보)\n",
    "          1020(동아일보)\n",
    "          1015(한국경제)\n",
    "          1009(매일경제)\n",
    "          1011(서울경제)\n",
    "        \n",
    "    Returns:\n",
    "        dict: 응답 데이터\n",
    "          sucess : 성공했거나 이미 중복 데이터거나\n",
    "          retry : 실패 > 재시도\n",
    "    \"\"\"\n",
    "    url = \"https://moluvalu.app.n8n.cloud/webhook/3fc6b155-45d8-42cb-b54b-c81bd87ac445\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"date\": date,\n",
    "        \"news_office_checked\": news_office_checked\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"요청 중 오류가 발생했습니다: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수집 중: 2025.06.30 - 뉴스사 1025\n",
      "2025.06.30 1025 결과: {'output': 'success\\n\\n뉴스 데이터가 {\"2025.06.30\", \"아모레퍼시픽\", \"090430\"}에 대해 정상적으로 입력되었습니다. (동일한 source가 이미 존재해도 success만 반환합니다.)'}\n",
      "수집 중: 2025.06.30 - 뉴스사 1020\n",
      "2025.06.30 1020 결과: {'output': 'sucess\\n\\n해당 뉴스 데이터가 정상적으로 입력(또는 이미 존재)하여 sucess를 반환합니다.'}\n",
      "수집 중: 2025.06.29 - 뉴스사 1025\n",
      "2025.06.29 1025 결과: {'output': '2025.06.29 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.29 - 뉴스사 1020\n",
      "2025.06.29 1020 결과: {'output': '알겠습니다. 주어진 요청에 따라 JSON 데이터가 제공되면, 아래와 같은 방식으로 처리하겠습니다.\\n\\n프로세스 요약:\\n\\n1. JSON 미제공 시: \"2025.06.29 에는 데이터가 없습니다\"를 반환합니다.\\n2. JSON 제공 시:\\n     - 뉴스 데이터에서 상장기업명을 추출합니다.\\n     - 상장기업명을 기준으로 종목코드를 찾아냅니다.\\n     - 종목코드가 없는 뉴스는 모두 버립니다.\\n     - 종목코드가 있는 뉴스만 다음 항목에 맞게 Supabase에 입력합니다:\\n         - title → fieldValues3_Field_Value\\n         - url(source) → fieldValues4_Field_Value\\n         - summary → fieldValues5_Field_Value\\n         - stock_code → fieldValues6_Field_Value\\n     - 모든 입력이 성공하면 success, 실패 시 retry를 반환합니다.\\n     - 이미 같은 source(뉴스 url)가 DB에 있다면 success만 반환합니다.\\n\\n다음부터 JSON 데이터를 제공해주시면 위 조건에 맞게 처리하겠습니다. JSON을 입력해 주세요!'}\n",
      "수집 중: 2025.06.28 - 뉴스사 1025\n",
      "2025.06.28 1025 결과: {'output': '2025.06.28 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.28 - 뉴스사 1020\n",
      "2025.06.28 1020 결과: {'output': '알겠습니다! 입력하신 조건 및 테이블 스키마에 따라, 다음과 같이 처리하겠습니다.\\n\\n설명 요약:\\n\\n- json 데이터가 주어지지 않을 경우 : \"2025.06.28 에는 데이터가 없습니다\" 라고 반환\\n- 정상적으로 supabase 입력 성공 시 : \"sucess\" 반환\\n- 실패 시 : \"retry\" 반환\\n- 이미 동일한 source가 있는 경우에도 \"sucess\" 반환\\n- 입력 시 필드 매핑\\n  - title → fieldValues3_Field_Value\\n  - url → fieldValues4_Field_Value\\n  - summery → fieldValues5_Field_Value\\n  - stock_code → fieldValues6_Field_Value\\n- (참고) \"해당 뉴스는 상장기업과 관련된 내용이 아니므로, 제공된 기준에 따라 필터링 대상에서 제외\" 라고 하셨는데, 이 경우에는 입력 처리를 하지 않겠습니다.\\n\\njson 입력을 기다리겠습니다!'}\n",
      "수집 중: 2025.06.27 - 뉴스사 1025\n",
      "2025.06.27 1025 결과: {'output': '2025.06.27 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.27 - 뉴스사 1020\n",
      "2025.06.27 1020 결과: {'output': '2025.06.27 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.26 - 뉴스사 1025\n",
      "2025.06.26 1025 결과: {'output': '2025.06.26 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.26 - 뉴스사 1020\n",
      "2025.06.26 1020 결과: {'output': '2025.06.26 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.25 - 뉴스사 1025\n",
      "2025.06.25 1025 결과: {'output': '2025.06.25 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.25 - 뉴스사 1020\n",
      "2025.06.25 1020 결과: {'output': '2025.06.25 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.24 - 뉴스사 1025\n",
      "2025.06.24 1025 결과: {'output': '이해했습니다.\\n\\n정리하자면, 사용자가 JSON 데이터를 입력하면 다음 조건과 매핑에 따라 supabase에 저장합니다:\\n\\n조건 및 반환 값:\\n- JSON이 주어지지 않으면 \"2025.06.24 에는 데이터가 없습니다\" 반환\\n- 저장 성공 시 \"sucess\" 반환\\n- 실패 시 \"retry\" 반환\\n- 이미 동일한 source(중복)일 경우도 \"sucess\"만 반환\\n\\n필드 매핑:\\n- fieldValues3_Field_Value ← title\\n- fieldValues4_Field_Value ← url\\n- fieldValues5_Field_Value ← summary\\n- fieldValues6_Field_Value ← stock_code\\n\\n또한, 모든 뉴스는 종목 코드를 찾을 수 없거나 상장기업과 관련 없으므로, 입력값의 stock_code 필드는 null이 될 수 있습니다.\\n\\n뉴스 JSON 데이터를 입력해 주시면 바로 처리하겠습니다.'}\n",
      "수집 중: 2025.06.24 - 뉴스사 1020\n",
      "2025.06.24 1020 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.06.23 - 뉴스사 1025\n",
      "2025.06.23 1025 결과: {'output': '2025.06.23 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.23 - 뉴스사 1020\n",
      "2025.06.23 1020 결과: {'output': '알겠습니다! 아래의 규칙을 적용하여 주어진 json을 Supabase에 입력하겠습니다.\\n\\n1. json이 입력되지 않으면 \"2025.06.23 에는 데이터가 없습니다\"를 반환\\n2. 데이터 입력 성공 시 \"success\"를, 실패 시 \"retry\"를 반환\\n3. 이미 동일한 source(중복 데이터)여도 \"success\"만 반환\\n4. 매핑:\\n   - title → fieldValues3_Field_Value\\n   - url → fieldValues4_Field_Value\\n   - summary → fieldValues5_Field_Value\\n   - stock_code → fieldValues6_Field_Value\\n\\n뉴스 데이터 중 주식과 관련됐으나 상장된 관련 회사를 찾을 수 없었다면 해당 뉴스는 모두 저장하지 않습니다.\\n\\n이제 json 데이터를 입력해 주세요.'}\n",
      "수집 중: 2025.06.22 - 뉴스사 1025\n",
      "2025.06.22 1025 결과: {'output': '2025.06.22 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.22 - 뉴스사 1020\n",
      "2025.06.22 1020 결과: {'output': '안내해주신 내용을 바탕으로 아래와 같이 처리하겠습니다.\\n\\n1. json이 입력되지 않으면 \"2025.06.22 에는 데이터가 없습니다\"를 반환합니다.\\n2. json이 입력되면\\n   - 해당 데이터의 title → fieldValues3_Field_Value\\n   - url → fieldValues4_Field_Value\\n   - summary → fieldValues5_Field_Value\\n   - stock_code → fieldValues6_Field_Value\\n   에 각각 매핑하여 Supabase 테이블에 입력합니다.\\n3. 이미 동일 source(즉 url) 데이터가 있더라도 성공(sucess)을 반환합니다.\\n4. 실패 시 retry를 반환합니다.\\n5. \"모든 뉴스는 버려진다\"는 가정에 따라, 상장기업(stock_code) 관련 정보가 없다면 데이터 입력을 진행하지 않습니다.\\n\\n아래와 같이 처리 규칙을 적용할 수 있습니다.  \\n뉴스 데이터(json)와 관련된 입력을 주세요.  \\n(지금은 실제 json 데이터가 없으므로 아무것도 입력하지 않습니다.)\\n\\n예시\\n---\\n입력 데이터가 없을 시:  \\n→ \"2025.06.22 에는 데이터가 없습니다\" 반환\\n\\n입력 데이터가 올바르게 주어지고 관련 stock_code도 있는 경우:  \\n→ 입력 수행, 성공시 sucess 반환, 실패시 retry 반환\\n\\n관련 상장기업(stock_code) 정보가 없는 모든 뉴스에 대해:  \\n→ 아무 입력도 하지 않음(즉, 데이터가 버려짐)\\n\\n필요하신 경우 실제 json 데이터를 입력해 주세요. 입력이 없다면 \"2025.06.22 에는 데이터가 없습니다\"로 답변하겠습니다.'}\n",
      "수집 중: 2025.06.21 - 뉴스사 1025\n",
      "2025.06.21 1025 결과: {'output': '알겠습니다! 다음에 입력되는 JSON 데이터를 기다리겠습니다.\\n\\n참고로:\\n- JSON 데이터가 제공되지 않으면 \"2025.06.21 에는 데이터가 없습니다\"를 반환합니다.\\n- 성공 시 \"success\", 실패 시 \"retry\"를 반환합니다.\\n- 이미 같은 source가 있을 때도 \"success\"만 반환합니다.\\n- 실제 데이터 입력 시 매핑 규칙을 유지하겠습니다.\\n\\n필요한 데이터를 제공해주시면 처리하겠습니다!'}\n",
      "수집 중: 2025.06.21 - 뉴스사 1020\n",
      "2025.06.21 1020 결과: {'output': '안내하신 조건에 따라 입력받은 JSON 데이터를 Supabase에 처리하겠습니다.\\n\\n정리:\\n\\n- JSON 데이터가 없는 경우: \"2025.06.21 에는 데이터가 없습니다\" 반환\\n- 입력 시 중복(source 기준) 허용 → 성공(success) 반환\\n- 실패 시: retry 반환\\n- title→fieldValues3_Field_Value, url→fieldValues4_Field_Value, summery→fieldValues5_Field_Value, stock_code→fieldValues6_Field_Value 매핑\\n- 상장기업(stock_code 존재) 뉴스만 입력, 없으면 해당 뉴스 버림\\n\\n뉴스 데이터를 전달해주시면, 요청하신 대로 처리하겠습니다.  \\n만약 데이터를 전달하지 않으셨다면, \"2025.06.21 에는 데이터가 없습니다\"를 바로 반환하겠습니다.\\n\\n뉴스 데이터를 입력해 주세요!'}\n",
      "수집 중: 2025.06.20 - 뉴스사 1025\n",
      "2025.06.20 1025 결과: {'output': '네, 안내해주신 내용을 정리하면 다음과 같습니다.\\n\\n- 입력받을 JSON에 종목 코드(stock_code)가 없는 경우, 해당 뉴스 데이터는 Supabase에 저장하지 않고 무시합니다.\\n- 만일 JSON이 주어지지 않을 경우(입력 데이터 없음), \"2025.06.20 에는 데이터가 없습니다\"를 반환합니다.\\n- 데이터 입력 시 성공하면 sucess, 실패하면 retry를 반환합니다.\\n- 삽입 시 소스(source)가 이미 존재해도 sucess만 반환합니다.\\n- 입력 매핑(필드)은 다음과 같습니다:\\n  - title → fieldValues3_Field_Value\\n  - url → fieldValues4_Field_Value (news source 링크)\\n  - summary → fieldValues5_Field_Value\\n  - stock_code → fieldValues6_Field_Value\\n\\n이렇게 처리하면 될까요? 예시 JSON이나 바로 처리할 JSON 데이터를 입력해주시면, 안내해드린 대로 실행하겠습니다!'}\n",
      "수집 중: 2025.06.20 - 뉴스사 1020\n",
      "2025.06.20 1020 결과: {'output': '알겠습니다. 다음 규칙으로 처리하겠습니다.\\n\\n- json이 주어지지 않으면: \"2025.06.20 에는 데이터가 없습니다\" 반환\\n- 성공적으로 입력시: success 반환\\n- 실패시: retry 반환\\n- 동일한 source가 이미 있으면: success 반환\\n- 입력 매핑\\n  - title → fieldValues3_Field_Value\\n  - url → fieldValues4_Field_Value\\n  - summery → fieldValues5_Field_Value\\n  - stock_code → fieldValues6_Field_Value\\n\\n그리고 입력 예시 json이나 실제 데이터를 받기 전까지 처리하지 않겠습니다.\\n\\n방금 받은 메시지는 “주어진 뉴스 중 상장기업과 관련된 뉴스를 찾을 수 없었다”는 안내이므로, 현재 데이터 입력 수행이 필요하지 않습니다. 앞으로 json을 주시면 안내한 매핑과 규칙대로 입력 처리하겠습니다. 필요한 json 데이터를 입력해 주세요.'}\n",
      "수집 중: 2025.06.19 - 뉴스사 1025\n",
      "2025.06.19 1025 결과: {'output': '네, 이해했습니다. 입력 규칙 및 필드 매핑 방법을 숙지하였습니다.\\n\\n정리:\\n- json 미제공 시 \"2025.06.19 에는 데이터가 없습니다\" 반환\\n- 입력 성공 시 sucess 반환, 실패 시 retry 반환\\n- 이미 source가 있더라도 sucess 반환\\n- 필드 매핑:\\n    - title → fieldValues3_Field_Value\\n    - url → fieldValues4_Field_Value\\n    - summary → fieldValues5_Field_Value\\n    - stock_code → fieldValues6_Field_Value\\n- 기사에 상장 기업명이 포함되어 있어야만 주식코드 식별 및 입력 가능\\n\\n준비되었습니다. json 데이터를 제공해주시면 규칙에 따라 처리하겠습니다.'}\n",
      "수집 중: 2025.06.19 - 뉴스사 1020\n",
      "2025.06.19 1020 결과: {'output': '알겠습니다! 아래의 입력 규칙과 결과 처리 로직을 이해하였습니다.\\n\\n요약:\\n\\n- json 데이터가 입력되지 않으면 \"2025.06.19 에는 데이터가 없습니다\" 반환\\n- 성공 시 \"sucess\", 실패 시 \"retry\" 반환\\n- 이미 동일한 source가 있으면 중복 등록 없이 \"sucess\"만 반환\\n- 필드 매핑 규칙도 숙지하였음\\n\\n아래와 같이 처리할 예정입니다:\\n\\n- json 데이터 입력 시: 필드 매핑 후 Supabase에 저장 시도\\n- 입력 실패: retry\\n- 성공 및 중복: sucess\\n\\n이제 입력하실 json 데이터를 주시면 저장 작업을 진행하겠습니다.'}\n",
      "수집 중: 2025.06.18 - 뉴스사 1025\n",
      "2025.06.18 1025 결과: {'output': '2025.06.18 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.18 - 뉴스사 1020\n",
      "2025.06.18 1020 결과: {'output': '2025.06.18 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.17 - 뉴스사 1025\n",
      "2025.06.17 1025 결과: {'output': '알겠습니다. 다음에 json 데이터가 주어지면 입력 규칙과 테이블 스키마에 맞게 Supabase에 저장을 시도하겠습니다.\\n\\n요약 정리:\\n\\n- json이 주어지지 않은 경우: \"2025.06.17 에는 데이터가 없습니다\"를 반환\\n- 성공적으로 저장하거나 이미 source가 있는 경우: sucess 반환\\n- 실패시: retry 반환\\n- 필드 매핑\\n  - fieldValues3_Field_Value: title\\n  - fieldValues4_Field_Value: url\\n  - fieldValues5_Field_Value: summary\\n  - fieldValues6_Field_Value: stock_code\\n\\n뉴스데이터(json)를 제공해주시면 입력을 진행하겠습니다.'}\n",
      "수집 중: 2025.06.17 - 뉴스사 1020\n",
      "2025.06.17 1020 결과: {'output': '2025.06.17 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.16 - 뉴스사 1025\n",
      "2025.06.16 1025 결과: {'output': '2025.06.16 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.16 - 뉴스사 1020\n",
      "2025.06.16 1020 결과: {'output': '알겠습니다.\\n\\n- 만약 주어지는 JSON이 없다면: \"2025.06.16 에는 데이터가 없습니다\"를 반환합니다.\\n- 만약 JSON이 주어진다면:\\n  - 상장기업과 관련된 뉴스만 필터링하고, 종목코드를 찾아야 합니다.\\n  - 이번 케이스에서는 \"상장기업에 관한 뉴스가 없으므로 모든 뉴스를 버리고 정리할 필요가 없다\"고 명시하셨으니, 입력/저장 작업을 수행하지 않습니다.\\n\\n따라서, JSON이 주어지더라도 이번 케이스에서는 아무 작업도 하지 않고 응답하지 않습니다.\\n\\n만약 실제로 JSON이 주어진다면 다시 알려주세요!  \\n지시에 따라 처리하겠습니다.'}\n",
      "수집 중: 2025.06.15 - 뉴스사 1025\n",
      "2025.06.15 1025 결과: {'output': '알겠습니다! json 데이터가 아직 주어지지 않았으므로 아래와 같이 안내드립니다.\\n\\n2025.06.15 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.15 - 뉴스사 1020\n",
      "2025.06.15 1020 결과: {'output': '2025.06.15 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.14 - 뉴스사 1025\n",
      "2025.06.14 1025 결과: {'output': '안내해 주신 내용을 기준으로, 입력받은 JSON 데이터를 Supabase의 raw_news_data 테이블에 아래 방식으로 입력하겠습니다.\\n\\n- JSON이 주어지지 않을 경우: \"2025.06.14 에는 데이터가 없습니다\" 를 반환합니다.\\n- 삽입 성공 시: \"success\" 반환\\n- 삽입 실패 시: \"retry\" 반환\\n- 만약 이미 동일한 source(중복 데이터)가 있는 경우에도 \"success\"만을 반환합니다.\\n\\n매핑 정보:\\n\\n- JSON의 title → fieldValues3_Field_Value\\n- JSON의 url → fieldValues4_Field_Value (source 필드에 해당)\\n- JSON의 summery → fieldValues5_Field_Value\\n- JSON의 stock_code → fieldValues6_Field_Value\\n\\n또한, 관련된 상장기업(즉, stock_code)이 없는 경우 해당 뉴스는 테이블에 삽입하지 않습니다.\\n\\n추가 뉴스 데이터가 있다면, 해당 기업 이름과 함께 제공해 주시면 처리해드릴 수 있습니다.\\n\\n뉴스 JSON 데이터를 입력해 주세요!'}\n",
      "수집 중: 2025.06.14 - 뉴스사 1020\n",
      "2025.06.14 1020 결과: {'output': '알겠습니다! 뉴스 데이터를 처리하기 위해 json 형식의 뉴스를 입력해 주세요.  \\n아직 json이 입력되지 않았으므로, 예시와 같이:\\n\\n{\\n  \"title\": \"삼성전자 주가 급등\",\\n  \"url\": \"https://news.example.com/article123\",\\n  \"summary\": \"삼성전자 주가가 오늘 크게 올랐습니다.\",\\n  \"stock_code\": \"005930\"\\n}\\n\\n와 같은 형식으로 입력해 주세요.  \\n만약 입력이 없다면 2025.06.14 에는 데이터가 없습니다를 반환하게 됩니다.\\n\\n뉴스 데이터를 입력해 주세요!'}\n",
      "수집 중: 2025.06.13 - 뉴스사 1025\n",
      "2025.06.13 1025 결과: {'output': '2025.06.13 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.13 - 뉴스사 1020\n",
      "2025.06.13 1020 결과: {'output': '알겠습니다.\\n\\n입력하신 규칙에 따르면, json 데이터가 주어지지 않았으므로 아래와 같이 답변합니다.\\n\\n2025.06.13 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.12 - 뉴스사 1025\n",
      "2025.06.12 1025 결과: {'output': '알겠습니다. 주어진 조건을 요약하면 다음과 같습니다.\\n\\n1. JSON 데이터가 없으면 \"2025.06.12 에는 데이터가 없습니다\" 반환\\n2. 입력 성공 시 \"sucess\" 반환, 실패 시 \"retry\" 반환\\n3. 이미 동일한 source 데이터가 있어도 \"sucess\" 반환\\n4. 필드 매핑은 다음과 같이 수행\\n   - title → fieldValues3_Field_Value\\n   - url → fieldValues4_Field_Value (테이블의 source 컬럼에 매핑)\\n   - summery → fieldValues5_Field_Value\\n   - stock_code → fieldValues6_Field_Value\\n\\n추가 안내:\\n- 상장기업이 없거나 종목 코드를 찾을 수 없는 경우, 해당 뉴스는 저장하지 않습니다.\\n\\n이제 실제 JSON 뉴스 데이터를 주시면, 위 규칙에 따라 Supabase에 적절히 입력하겠습니다.'}\n",
      "수집 중: 2025.06.12 - 뉴스사 1020\n",
      "2025.06.12 1020 결과: {'output': '알겠습니다. 안내해주신 내용을 기반으로 아래와 같이 처리합니다.\\n\\n1. JSON이 주어지지 않으면 \"2025.06.12 에는 데이터가 없습니다\"를 반환합니다.\\n2. JSON이 주어지고, 입력이 성공하거나 이미 동일 source 데이터가 있는 경우에는 \"sucess\"를 반환합니다.\\n3. 입력이 실패할 경우에는 \"retry\"를 반환합니다.\\n4. 필드 매핑은 아래와 같습니다:\\n\\n- fieldValues3_Field_Value : title\\n- fieldValues4_Field_Value : url (→ source로 이해)\\n- fieldValues5_Field_Value : summary\\n- fieldValues6_Field_Value : stock_code\\n\\n또한, 뉴스 데이터가 상장기업과 관련이 없는 것으로 간주되면 삭제된 뉴스로 판단하겠습니다.\\n\\n뉴스 json 데이터를 입력해주시면, 처리 진행하겠습니다.  \\n추가로 요청하실 작업이 있으시면 말씀해 주세요!'}\n",
      "수집 중: 2025.06.11 - 뉴스사 1025\n",
      "2025.06.11 1025 결과: {'output': '2025.06.11 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.11 - 뉴스사 1020\n",
      "2025.06.11 1020 결과: {'output': '입력하신 조건과 설명에 따르면:\\n- 모든 뉴스가 상장기업과 관련 없으며, 기업명으로부터 주식코드를 추출할 수 없습니다.\\n- 따라서 news 데이터를 Supabase에 입력할 때, stock_code 필드는 null 또는 빈 값(\"\")으로 입력해야 합니다.\\n\\n만약 지금 json 데이터가 주어지지 않았다면, 규칙에 따라 \"2025.06.11 에는 데이터가 없습니다\"라고 응답해야 합니다.\\n\\n입력할 json이 있다면, 각 항목의 필드 매핑은 다음과 같습니다:\\n- title → fieldValues3_Field_Value\\n- url → fieldValues4_Field_Value (source와 동일하면 같이 사용)\\n- summary → fieldValues5_Field_Value\\n- stock_code → fieldValues6_Field_Value (항상 null 또는 빈 문자열 입력)\\n\\n다음과 같이 처리방안을 요약합니다:\\n\\n1. json 데이터가 없으면:\\n    → 2025.06.11 에는 데이터가 없습니다\\n\\n2. json 데이터가 있으면:\\n    - 각각의 뉴스 data에서\\n        - title, url/source, summary는 json에서 추출\\n        - stock_code는 null(혹은 빈 문자열)로 입력\\n    - 중복(source 기준 PK) 존재 시에도 sucess 반환\\n    - 입력 실패 시 retry 반환\\n\\njson 예시가 주어지면 바로 Supabase 입력 코드를 실행하겠습니다. json 데이터를 입력해 주세요.'}\n",
      "수집 중: 2025.06.10 - 뉴스사 1025\n",
      "2025.06.10 1025 결과: {'output': '2025.06.10 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.10 - 뉴스사 1020\n",
      "2025.06.10 1020 결과: {'output': '2025.06.10 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.09 - 뉴스사 1025\n",
      "2025.06.09 1025 결과: {'output': '알겠습니다. 아래와 같이 처리하겠습니다.\\n\\n- json 데이터가 주어지지 않은 경우에는 \"2025.06.09 에는 데이터가 없습니다\"를 반환합니다.\\n- json 데이터가 들어올 경우, 스키마에 맞게 필드 매핑을 하여 Supabase에 입력 시도합니다.\\n- 동일한 source가 이미 존재해도 성공(sucess)만 반환합니다.\\n- 만약 입력에 실패하면 retry를 반환합니다.\\n- 이번 경우에는 주어진 기업(\"대주그룹\", \"국립현대미술관\") 모두 상장사 아님을 파악하여, 모든 뉴스를 실제로는 입력하지 않습니다.\\n\\n추가로 입력할 json 데이터가 있다면 말씀해 주세요. 없다면, \"2025.06.09 에는 데이터가 없습니다\"를 반환합니다.'}\n",
      "수집 중: 2025.06.09 - 뉴스사 1020\n",
      "2025.06.09 1020 결과: {'output': '2025.06.09 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.08 - 뉴스사 1025\n",
      "2025.06.08 1025 결과: {'output': '네, 이해했습니다.\\n\\n요약:\\n\\n- 입력되는 JSON이 없으면 \"2025.06.08 에는 데이터가 없습니다\"라고 반환합니다.\\n- JSON이 주어지고 입력 성공시 \"sucess\"(성공) 혹은 \"retry\"(실패)로 응답합니다.\\n- source(뉴스의 고유 URL)가 이미 DB에 있다면 단순 \"sucess\"로 처리합니다.\\n- 스키마 매핑:\\n  - title → fieldValues3_Field_Value\\n  - url → fieldValues4_Field_Value (source)\\n  - summary → fieldValues5_Field_Value\\n  - stock_code → fieldValues6_Field_Value\\n\\n상장 기업 관련 뉴스 구분 부분도 이해했습니다. 실제 뉴스에서 회사명이 드러나야만 stock_code를 매핑할 수 있습니다.\\n\\n이제 JSON을 주시면 위의 방식대로 처리하겠습니다. JSON 데이터가 없다면 \"2025.06.08 에는 데이터가 없습니다\"만 반환하겠습니다.\\n\\nJSON을 입력해 주세요.'}\n",
      "수집 중: 2025.06.08 - 뉴스사 1020\n",
      "2025.06.08 1020 결과: {'output': '뉴스 데이터(json)가 제공되지 않았습니다.\\n\\n2025.06.08 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.07 - 뉴스사 1025\n",
      "2025.06.07 1025 결과: {'output': 'retry\\n\\n뉴스 데이터에 명확한 상장기업명이 없어 주식 코드를 공란(\"\")으로 입력했으나, 테이블의 foreign key 제약조건에 따라 stock_code는 companies 테이블의 값이어야 하므로 입력에 실패하였습니다. 상장기업 관련 뉴스일 경우 기업명과 해당 기업의 주식 코드가 반드시 필요합니다.'}\n",
      "수집 중: 2025.06.07 - 뉴스사 1020\n",
      "2025.06.07 1020 결과: {'output': '네, 뉴스 데이터를 입력해주시면, 해당 내용을 테이블 스키마에 맞게 아래와 같이 매핑하여 Supabase에 입력하겠습니다.\\n\\n맵핑 규칙:\\n- title → fieldValues3_Field_Value\\n- url → fieldValues4_Field_Value (source 컬럼)\\n- summery → fieldValues5_Field_Value (summary 컬럼)\\n- stock_code → fieldValues6_Field_Value\\n\\n뉴스 데이터를 알려주시면 바로 처리하겠습니다.'}\n",
      "수집 중: 2025.06.06 - 뉴스사 1025\n",
      "2025.06.06 1025 결과: {'output': '데이터를 입력하려면 json 데이터를 제공해 주세요.  \\n만약 입력할 데이터가 없으면 기준일자(예: 2025.06.06)에 대한 \"2025.06.06 에는 데이터가 없습니다\" 메시지를 반환합니다.\\n\\njson이 준비되면 아래 매핑 규칙에 따라 입력을 진행하겠습니다:\\n- fieldValues3_Field_Value = title\\n- fieldValues4_Field_Value = url (source)\\n- fieldValues5_Field_Value = summary\\n- fieldValues6_Field_Value = stock_code\\n\\n입력할 데이터를 주시면 처리를 이어가겠습니다.'}\n",
      "수집 중: 2025.06.06 - 뉴스사 1020\n",
      "2025.06.06 1020 결과: {'output': '2025.06.06 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.05 - 뉴스사 1025\n",
      "2025.06.05 1025 결과: {'output': '2025.06.05 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.05 - 뉴스사 1020\n",
      "2025.06.05 1020 결과: {'output': '2025.06.05 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.04 - 뉴스사 1025\n",
      "2025.06.04 1025 결과: {'output': '네, 이해했습니다.\\n\\n아래의 지침대로 동작하겠습니다.\\n\\n- json 데이터가 없으면 \"2025.06.04 에는 데이터가 없습니다\"를 반환합니다.\\n- json이 주어져 적절히 입력을 시도하고,\\n    - 성공적으로 입력하거나(혹은 이미 source가 존재하여 primary key에 위반되는 경우에도) \"sucess\"를 반환합니다.\\n    - 입력이 실패시 \"retry\"를 반환합니다.\\n- 매핑:\\n    - fieldValues3_Field_Value ← title\\n    - fieldValues4_Field_Value ← url\\n    - fieldValues5_Field_Value ← summery\\n    - fieldValues6_Field_Value ← stock_code\\n\\n뉴스 데이터에서 상장 기업에 대한 정보(주식 코드 등)가 누락되었을 경우, 필요한 데이터를 제공할 수 없음을 명확히 안내했습니다. 만약, 관련 기사나 상장기업 정보(주식 코드 등)가 포함된 새로운 json을 제공해주시면 그 정보를 기반으로 supabase에 입력 시도하겠습니다.\\n\\n이제 json 입력을 주시면 작업을 진행할 수 있습니다.'}\n",
      "수집 중: 2025.06.04 - 뉴스사 1020\n",
      "2025.06.04 1020 결과: {'output': '2025.06.04 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.03 - 뉴스사 1025\n",
      "2025.06.03 1025 결과: {'output': '2025.06.03 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.03 - 뉴스사 1020\n",
      "2025.06.03 1020 결과: {'output': '안내해 주신 내용을 정리하면 다음과 같습니다:\\n\\n- json 데이터가 주어지지 않은 경우 \"2025.06.03 에는 데이터가 없습니다\"를 반환\\n- 입력 데이터가 있을 경우, 상장기업과 관련 있어 주식 코드를 찾을 수 있을 때에만 Supabase에 입력\\n    - 입력 성공 시: \"sucess\" 반환\\n    - 실패 시: \"retry\" 반환\\n    - 동일 source(중복)일 경우에도 \"sucess\" 반환\\n- 입력 컬럼 및 매핑:\\n    - title → fieldValues3_Field_Value\\n    - url → fieldValues4_Field_Value\\n    - summery → fieldValues5_Field_Value\\n    - stock_code → fieldValues6_Field_Value\\n\\n현재 뉴스 데이터에서 상장기업 및 유효한 주식 코드를 찾지 못하여 등록할 데이터가 없습니다.\\n\\n추가 뉴스 데이터를 주시면 다시 진행하겠습니다.'}\n",
      "수집 중: 2025.06.02 - 뉴스사 1025\n",
      "2025.06.02 1025 결과: {'output': '알겠습니다. 아래와 같이 처리하겠습니다.\\n\\n- JSON 데이터가 주어지지 않을 경우: \"2025.06.02 에는 데이터가 없습니다\"를 반환합니다.\\n- 성공적으로 입력 시: success를 반환합니다.\\n- 실패 시: retry를 반환합니다.\\n- 이미 동일한 source(중복)가 있는 경우도 성공(success)으로 처리합니다.\\n\\n입력 시 맵핑은 다음과 같습니다:\\n- fieldValues3_Field_Value: title\\n- fieldValues4_Field_Value: url\\n- fieldValues5_Field_Value: summary\\n- fieldValues6_Field_Value: stock_code\\n\\nJSON 데이터를 보내주시면 바로 입력을 진행하겠습니다.'}\n",
      "수집 중: 2025.06.02 - 뉴스사 1020\n",
      "2025.06.02 1020 결과: {'output': '알겠습니다! 아래와 같이 처리 로직을 요약합니다.\\n\\n조건 및 처리 방식:\\n\\n1. 주어질 JSON이 없을 경우: \"2025.06.02 에는 데이터가 없습니다\" 반환\\n2. 성공적으로 입력되면: success 반환\\n3. 실패 시(예: 네트워크 오류 등): retry 반환\\n4. 이미 동일 source 데이터가 있으면: success 반환 (중복 입력 무시)\\n5. 입력 매핑 규칙\\n   - fieldValues3_Field_Value : title → title\\n   - fieldValues4_Field_Value : url → source\\n   - fieldValues5_Field_Value : summary → summery\\n   - fieldValues6_Field_Value : stock_code → stock_code\\n\\n또한, 주어진 데이터에서 상장기업 관련 뉴스가 없을 경우 안내 문구처럼 추가정보 요청 메시지를 출력합니다.\\n\\n예시 처리 플로우:\\n\\n- 뉴스 JSON이 입력되면: fieldValues에 맞춰 mapping → Supabase 입력 → 결과에 따라 success/retry 반환\\n- 뉴스 JSON이 없으면: \"2025.06.02 에는 데이터가 없습니다\" 반환\\n- source 중복 시: success 반환\\n- 상장기업 관련 뉴스가 없을 경우: \"현재 주어진 뉴스 데이터에서는 상장기업과 관련된 뉴스를 필터링할 수 있는 정보를 제공받지 못했습니다...\" 메시지 출력\\n\\n이제 실제 JSON 데이터를 입력해주시면 위 로직에 따라 처리하겠습니다!'}\n",
      "수집 중: 2025.06.01 - 뉴스사 1025\n",
      "2025.06.01 1025 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.06.01 - 뉴스사 1020\n",
      "2025.06.01 1020 결과: {'output': '알겠습니다. 아래와 같은 방식으로 진행하겠습니다.\\n\\n- json이 주어지지 않으면 \"2025.06.01 에는 데이터가 없습니다\"를 반환합니다.\\n- json이 주어지면, 해당 데이터를 Supabase에 입력 시도합니다.\\n- 성공 시에는 success, 실패 시에는 retry 문자열을 반환합니다.\\n- 이미 동일한 source 데이터(중복)가 있는 경우에도 success를 반환합니다.\\n\\n테이블 스키마에 따라, 필드 매핑은 다음과 같이 이루어집니다:\\n- title → fieldValues3_Field_Value\\n- url → fieldValues4_Field_Value\\n- summary → fieldValues5_Field_Value\\n- stock_code → fieldValues6_Field_Value (없을 경우 null 값을 사용)\\n\\n또한, 최근 뉴스 중 상장기업과 관련된 것은 \\'삼성반도체\\' 관련 뉴스였으나, 해당 기업의 정확한 주식코드를 찾을 수 없으므로, 관련 뉴스 데이터도 결과적으로 없습니다.  \\n\\njson 데이터를 주시면 위의 정책에 따라 입력을 시도하겠습니다.  \\njson이 없으면 \"2025.06.01 에는 데이터가 없습니다\"를 반환합니다.'}\n",
      "수집 중: 2025.05.31 - 뉴스사 1025\n",
      "2025.05.31 1025 결과: {'output': '안내 감사합니다! 이제 뉴스 데이터(JSON 형식 등)를 입력해주시면, 말씀하신 스키마와 필드 매핑 기준에 맞춰 Supabase에 저장을 시도하겠습니다.\\n\\n만약 뉴스를 입력하지 않으시면 “2025.05.31 에는 데이터가 없습니다”라는 메시지를 반환할 것입니다.\\n\\n뉴스를 입력해 주세요!'}\n",
      "수집 중: 2025.05.31 - 뉴스사 1020\n",
      "2025.05.31 1020 결과: {'output': '알겠습니다. 앞으로 json 데이터가 주어지지 않을 경우 \"2025.05.31 에는 데이터가 없습니다\"를 반환하겠습니다.\\n\\n또한, 입력받은 뉴스가 상장 기업과 관련이 없어서 stock_code가 없을 경우, 해당 뉴스를 제외하고 저장하지 않겠습니다. 만약 추가적으로 크롤링된 뉴스 처리가 필요하다면 말씀해 주세요.\\n\\n규칙대로 json 데이터가 주어지면 스키마에 맞추어 아래와 같이 저장 프로세스를 실행하겠습니다.\\n\\n- title → fieldValues3_Field_Value\\n- url → fieldValues4_Field_Value\\n- summery → fieldValues5_Field_Value\\n- stock_code → fieldValues6_Field_Value\\n\\n준비 완료되었습니다. 처리할 뉴스 json을 입력해 주세요.'}\n",
      "수집 중: 2025.05.30 - 뉴스사 1025\n",
      "2025.05.30 1025 결과: {'output': '입력받을 JSON 데이터가 주어지지 않았으니 아래와 같이 답변합니다.\\n\\n2025.05.30 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.30 - 뉴스사 1020\n",
      "2025.05.30 1020 결과: {'output': 'success\\n\\n입력하신 데이터가 정상적으로 Supabase에 입력되었습니다. 동일한 source 데이터가 이미 존재해도 \"success\"만을 반환합니다.\\n\\n필요한 추가 작업이 있다면 말씀해 주세요.'}\n",
      "수집 중: 2025.05.29 - 뉴스사 1025\n",
      "2025.05.29 1025 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.29 - 뉴스사 1020\n",
      "2025.05.29 1020 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.28 - 뉴스사 1025\n",
      "2025.05.28 1025 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.28 - 뉴스사 1020\n",
      "2025.05.28 1020 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.05.27 - 뉴스사 1025\n",
      "2025.05.27 1025 결과: {'output': '2025.05.27 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.27 - 뉴스사 1020\n",
      "2025.05.27 1020 결과: {'output': '뉴스 데이터에서 상장기업과 관련된 정보를 찾을 수 없으므로, 입력값이 없거나 주식 코드(stock_code)가 없는 경우로 인식됩니다.\\n\\n요구하신 가이드에 따라 아래와 같이 응답합니다:\\n\\n2025.05.27 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.26 - 뉴스사 1025\n",
      "2025.05.26 1025 결과: {'output': '알겠습니다! 앞으로 주어질 JSON 데이터를 다음과 같이 처리하겠습니다:\\n\\n- JSON이 제공되지 않으면 \"2025.05.26 에는 데이터가 없습니다\"를 반환합니다.\\n- 성공적으로 입력되면 \"success\"를, 실패 시 \"retry\"를 반환합니다.\\n- 이미 동일한 source(예: url)이 존재하면 \"success\"만 반환합니다.\\n- 필드 매핑은 아래와 같이 합니다:\\n\\n| 테이블 컬럼 | JSON Key (예시) | Supabase Field         |\\n|--------------|---------------------|---------------------------|\\n| title        | title               | fieldValues3_Field_Value  |\\n| source       | url                 | fieldValues4_Field_Value  |\\n| summary      | summary             | fieldValues5_Field_Value  |\\n| stock_cord   | stock_code          | fieldValues6_Field_Value  |\\n\\nJSON을 제공해주시면, 예시 처리 과정을 보여드릴 수 있습니다!'}\n",
      "수집 중: 2025.05.26 - 뉴스사 1020\n",
      "2025.05.26 1020 결과: {'output': '이해했습니다.\\n\\n요약하자면:\\n\\n- 입력으로 JSON 데이터가 오지 않으면 \"2025.05.26 에는 데이터가 없습니다\"라는 메시지를 반환합니다.\\n- JSON이 정상적으로 입력되면 주어진 필드( title → fieldValues3_Field_Value, url → fieldValues4_Field_Value, summary → fieldValues5_Field_Value, stock_code → fieldValues6_Field_Value )에 데이터를 넣어 Supabase에 저장합니다.\\n- 정상 저장(또는 이미 동일한 source가 존재)시엔 success를, 실패시엔 retry를 반환합니다.\\n- 뉴스 데이터가 상장기업과 관련이 없거나 주식코드가 없다고 명확히 언급된 기사는 모두 제외(즉, 입력하지 않음)합니다.\\n\\n이제 JSON 데이터를 입력해 주세요. (또는 원하신 경우 테스트하실 내용을 알려주세요.)'}\n",
      "수집 중: 2025.05.25 - 뉴스사 1025\n",
      "2025.05.25 1025 결과: {'output': '2025.05.25 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.25 - 뉴스사 1020\n",
      "2025.05.25 1020 결과: {'output': '2025.05.25 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.24 - 뉴스사 1025\n",
      "2025.05.24 1025 결과: {'output': '2025.05.24 에는 데이터가 없습니다.'}\n",
      "수집 중: 2025.05.24 - 뉴스사 1020\n",
      "2025.05.24 1020 결과: {'output': '요청하신 가이드에 따라, 다음과 같이 처리하겠습니다.\\n\\n- json 데이터가 없는 경우 → \"2025.05.24 에는 데이터가 없습니다\"\\n- 정상적으로 입력되면 → \"sucess\"\\n- 실패하면 → \"retry\"\\n- 중복(source)이어도 → \"sucess\"\\n- provided field 매핑:\\n    - title → fieldValues3_Field_Value\\n    - url(source) → fieldValues4_Field_Value\\n    - summary → fieldValues5_Field_Value\\n    - stock_code → fieldValues6_Field_Value\\n\\n뉴스에서 상장기업명을 추출하고 싶으면, 뉴스 제목에 명확히 기재된 기업명이 필요합니다. (예: “삼성전자, 신제품 출시...”, “현대차, 신기술 도입” 등)\\n\\n현재 제공하신 예시 뉴스에서는 특정 상장 기업명을 추정하거나 확인할 수 없어 종목코드 매핑이 불가합니다.\\n\\n관련된 json이 주어지면 언제든 입력 가능합니다. 입력할 데이터 또는 상장사명/종목코드가 명확히 포함된 예시 json을 주시면 아래와 같이 처리하여 Supabase에 입력할 수 있습니다.\\n\\n(예시 json 필요시 아래 형식 참고)\\n{\\n  \"title\": \"삼성전자, 반도체 신기술 공개\",\\n  \"url\": \"https://example.com/article/1234\",\\n  \"summary\": \"삼성전자가 혁신적인 반도체 기술을 선보였다.\",\\n  \"stock_code\": \"005930\"\\n}\\n\\n원하시는 데이터를 제공해주시면 바로 처리하겠습니다!'}\n",
      "수집 중: 2025.05.23 - 뉴스사 1025\n",
      "2025.05.23 1025 결과: {'output': '2025.05.23 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.23 - 뉴스사 1020\n",
      "2025.05.23 1020 결과: {'output': '2025.05.23 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.22 - 뉴스사 1025\n",
      "2025.05.22 1025 결과: {'output': '2025.05.22 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.22 - 뉴스사 1020\n",
      "2025.05.22 1020 결과: {'output': '2025.05.22 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.21 - 뉴스사 1025\n",
      "2025.05.21 1025 결과: {'output': 'success\\n\\n입력하신 데이터는 정상적으로 Supabase에 반영되었습니다.  \\n- title → \"소비자들 \\'SKT 해킹 사태 관련 가장 큰 우려는 금융사기\\'\"\\n- url → \"https://www.joongang.co.kr/article/25337637\"\\n- summary → \"SK텔레콤 해킹 사고와 관련해 소비자들은 계좌 탈취 등 금융사기가 발생할 것을 가장 우려한다는 조사 결과가 나왔다.\"\\n- stock_code → \"017670\"\\n\\n질문 또는 추가 데이터가 있으시면 언제든 요청해주세요.'}\n",
      "수집 중: 2025.05.21 - 뉴스사 1020\n",
      "2025.05.21 1020 결과: {'output': '2025.05.21 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.20 - 뉴스사 1025\n",
      "2025.05.20 1025 결과: {'output': '2025.05.20 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.20 - 뉴스사 1020\n",
      "2025.05.20 1020 결과: {'output': '2025.05.20 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.19 - 뉴스사 1025\n",
      "2025.05.19 1025 결과: {'output': 'sucess\\n\\n입력하신 뉴스가 정상적으로 Supabase에 입력되었습니다. 동일한 source 데이터가 이미 존재하더라도 성공 처리됩니다.'}\n",
      "수집 중: 2025.05.19 - 뉴스사 1020\n",
      "2025.05.19 1020 결과: {'output': '네, 안내해주신 방법에 따라 처리하겠습니다.\\n\\n- json 뉴스 데이터가 주어지지 않은 경우: \"2025.05.19 에는 데이터가 없습니다\" 를 반환합니다.\\n- json 뉴스 데이터가 주어질 경우, 상장기업이 명확히 추출되면 해당 기업의 종목코드를 찾아 입력 필드에 맞게 Supabase에 저장합니다.\\n- 성공 시 \"success\", 실패 시 \"retry\"를 반환합니다. 이미 source 중복이어도 \"success\"를 반환합니다.\\n\\n뉴스 데이터나 json이 주어지지 않았으니, 아래와 같이 답변합니다.\\n\\n2025.05.19 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.18 - 뉴스사 1025\n",
      "2025.05.18 1025 결과: {'output': '2025.05.18 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.18 - 뉴스사 1020\n",
      "2025.05.18 1020 결과: {'output': '네, 안내해 주신 조건과 테이블 스키마, 매핑 규칙을 반영해서 json 입력을 준비하겠습니다.\\n\\n- 만약 json이 제공되지 않으면: \"2025.05.18 에는 데이터가 없습니다\"를 반환\\n- 성공 시: success\\n- 실패 시: retry\\n- 이미 source가 있으면: success\\n- 필드 매핑:  \\n  - fieldValues3_Field_Value ← title  \\n  - fieldValues4_Field_Value ← url  \\n  - fieldValues5_Field_Value ← summery  \\n  - fieldValues6_Field_Value ← stock_code\\n\\n추가로, SKT의 종목 코드를 찾지 못해서 해당 뉴스는 제외하겠다는 안내도 잘 이해했습니다. 만약 새로운 뉴스 데이터가 있다면 제공해 주시면 입력 처리를 진행하겠습니다.\\n\\n뉴스 JSON 데이터가 있다면 보내주세요!'}\n",
      "수집 중: 2025.05.17 - 뉴스사 1025\n",
      "2025.05.17 1025 결과: {'output': '2025.05.17 에는 데이터가 없습니다.'}\n",
      "수집 중: 2025.05.17 - 뉴스사 1020\n",
      "2025.05.17 1020 결과: {'output': '안내드린 내용 확인했습니다.\\n\\n- 주어진 json이 없으면 \"2025.05.17 에는 데이터가 없습니다\"를 반환합니다.\\n- 성공 시 \"sucess\", 실패 시 \"retry\"를 반환합니다.\\n- 이미 같은 source(원본링크)가 있어도 성공으로 처리합니다.\\n- 각 필드를 아래와 같이 매핑합니다:\\n    - fieldValues3_Field_Value: title\\n    - fieldValues4_Field_Value: url\\n    - fieldValues5_Field_Value: summary\\n    - fieldValues6_Field_Value: stock_code\\n\\n상장기업과 관련 없는 뉴스라면 입력하지 않습니다.\\n\\n이제 json 데이터를 입력해 주세요.'}\n",
      "수집 중: 2025.05.16 - 뉴스사 1025\n",
      "2025.05.16 1025 결과: {'output': 'success\\n\\n해당 데이터를 이미 source(https://www.joongang.co.kr/article/25336526) 기준으로 보유하고 있거나 새로 성공적으로 입력했습니다.'}\n",
      "수집 중: 2025.05.16 - 뉴스사 1020\n",
      "2025.05.16 1020 결과: {'output': '2025.05.16 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.15 - 뉴스사 1025\n",
      "2025.05.15 1025 결과: {'output': '알겠습니다.\\n\\n요청하신 방식 대로, 주어진 JSON이 없다면 \"2025.05.15 에는 데이터가 없습니다\"를 반환합니다. 만약 JSON이 주어지면 해당 JSON에서 title, url, summary, stock_code 값을 추출하여 Supabase에 다음과 같이 입력하겠습니다.\\n\\n- fieldValues3_Field_Value에는 title\\n- fieldValues4_Field_Value에는 url\\n- fieldValues5_Field_Value에는 summary\\n- fieldValues6_Field_Value에는 stock_code\\n\\n만약 동일한 source 데이터가 이미 있어도 \"success\"만을 반환하며, 입력에 실패하면 \"retry\"를 반환합니다.\\n\\n뉴스에서 상장기업의 주식 코드를 찾지 못했다면 stock_code는 null 값으로 입력하겠습니다.\\n\\nJSON을 입력해 주시면 처리하겠습니다.'}\n",
      "수집 중: 2025.05.15 - 뉴스사 1020\n",
      "2025.05.15 1020 결과: {'output': '2025.05.15 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.14 - 뉴스사 1025\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.05.14 1025 결과: {}\n",
      "수집 중: 2025.05.14 - 뉴스사 1020\n",
      "2025.05.14 1020 결과: {'output': '2025.05.14 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.13 - 뉴스사 1025\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.05.13 1025 결과: {}\n",
      "수집 중: 2025.05.13 - 뉴스사 1020\n",
      "2025.05.13 1020 결과: {'output': '2025.05.13 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.12 - 뉴스사 1025\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.05.12 1025 결과: {}\n",
      "수집 중: 2025.05.12 - 뉴스사 1020\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.05.12 1020 결과: {}\n",
      "수집 중: 2025.05.11 - 뉴스사 1025\n",
      "2025.05.11 1025 결과: {'output': '네! 다음에 JSON 데이터를 입력해주시면, 해당 데이터를 Supabase에 입력하도록 하겠습니다.\\n\\n정리하자면:\\n\\n- 만약 JSON이 주어지지 않으면 \"2025.05.11 에는 데이터가 없습니다\"를 반환합니다.\\n- JSON 데이터 입력이 성공하면 \"success\"를 반환합니다.\\n- 실패 시에는 \"retry\"를 반환합니다.\\n- 이미 동일한 source(뉴스 원본) 데이터가 있을 경우에도 \"success\"만 반환합니다.\\n\\nJSON 데이터를 입력해주시면 바로 처리하겠습니다!'}\n",
      "수집 중: 2025.05.11 - 뉴스사 1020\n",
      "2025.05.11 1020 결과: {'output': '네, 안내해주신 방식에 따라 뉴스 데이터를 정리하겠습니다. 뉴스 데이터의 JSON 목록을 입력해 주시면, 각 뉴스에 대해 상장기업 관련 여부를 판단하고 적절한 필드에 맞춰 Supabase에 입력하겠습니다.\\n\\n만약 JSON 데이터가 입력되지 않을 경우, \"2025.05.11 에는 데이터가 없습니다\"를 반환하겠습니다.\\n\\n뉴스 데이터를 JSON 형식으로 제공해 주세요.'}\n",
      "수집 중: 2025.05.10 - 뉴스사 1025\n",
      "2025.05.10 1025 결과: {'output': '2025.05.10 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.10 - 뉴스사 1020\n",
      "2025.05.10 1020 결과: {'output': '이해했습니다! 입력 조건을 다음과 같이 정리하겠습니다.\\n\\n- JSON(뉴스 데이터)이 주어지면 상장기업(stock_code)이 존재하는 경우에만 해당 테이블에 입력 시도\\n- 입력 시 title → fieldValues3_Field_Value, url → fieldValues4_Field_Value, summary → fieldValues5_Field_Value, stock_code → fieldValues6_Field_Value 에 매핑\\n- stock_code가 없다면 해당 뉴스는 입력 제외 (상장기업과 관련 없는 뉴스이므로)\\n- 데이터 미제공시 \"2025.05.10 에는 데이터가 없습니다\" 반환\\n- 입력 성공/동일 source 존재 시 success, 실패 시 retry 반환\\n\\n뉴스 데이터가 있다면 제공해 주세요!'}\n",
      "수집 중: 2025.05.09 - 뉴스사 1025\n",
      "2025.05.09 1025 결과: {'output': '2025.05.09 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.09 - 뉴스사 1020\n",
      "2025.05.09 1020 결과: {'output': '2025.05.09 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.08 - 뉴스사 1025\n",
      "2025.05.08 1025 결과: {'output': '안내해주신 조건과 테이블 스키마, 매핑 기준을 정확히 이해했습니다.\\n\\n추후 JSON 데이터가 주어질 경우 다음과 같이 처리하겠습니다:\\n\\n- JSON이 주어지지 않으면: \"2025.05.08 에는 데이터가 없습니다\" 반환\\n- 정상 입력(이미 있는 source여도): \"sucess\" 반환\\n- 입력 실패 시: \"retry\" 반환\\n- 기업명이 \"내무부\"인 경우에는 상장기업 관련 뉴스가 아니므로 결과에서 제외\\n\\n그리고,\\n- title → fieldValues3_Field_Value\\n- url → fieldValues4_Field_Value\\n- summery → fieldValues5_Field_Value\\n- stock_code → fieldValues6_Field_Value\\n\\n이 기준에 따라 입력을 시도하겠습니다. JSON 데이터를 주시면 계속 진행하겠습니다.'}\n",
      "수집 중: 2025.05.08 - 뉴스사 1020\n",
      "2025.05.08 1020 결과: {'output': '2025.05.08 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.07 - 뉴스사 1025\n",
      "2025.05.07 1025 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.07 - 뉴스사 1020\n",
      "2025.05.07 1020 결과: {'output': '2025.05.07 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.06 - 뉴스사 1025\n",
      "2025.05.06 1025 결과: {'output': '2025.05.06 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.06 - 뉴스사 1020\n",
      "2025.05.06 1020 결과: {'output': '2025.05.06 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.05 - 뉴스사 1025\n",
      "2025.05.05 1025 결과: {'output': '2025.05.05 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.05 - 뉴스사 1020\n",
      "2025.05.05 1020 결과: {'output': '2025.05.05 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.04 - 뉴스사 1025\n",
      "2025.05.04 1025 결과: {'output': '알겠습니다. 다음에 JSON 데이터가 주어질 때, 안내해주신 매핑과 조건에 따라 Supabase에 입력을 시도하고, 말씀하신 성공/실패 규칙에 맞게 응답하겠습니다.\\n\\n현재는 입력받은 JSON 데이터가 없으므로, “2025.05.04 에는 데이터가 없습니다”를 반환합니다. \\n\\nJSON 데이터를 제공해주시면, 다시 입력 처리를 진행하겠습니다.'}\n",
      "수집 중: 2025.05.04 - 뉴스사 1020\n",
      "2025.05.04 1020 결과: {'output': '뉴스데이터(JSON 형식)를 입력해주시면, 안내드린대로 Supabase에 적절히 입력하겠습니다.\\n\\n만약 입력할 JSON이 없다면 \"2025.05.04 에는 데이터가 없습니다\"라는 메시지를 반환합니다.\\n\\n뉴스데이터(JSON)를 제공해주세요!'}\n",
      "수집 중: 2025.05.03 - 뉴스사 1025\n",
      "2025.05.03 1025 결과: {'output': '알겠습니다. 앞으로 주어지는 JSON 데이터가 없을 경우에는 \"2025.05.03 에는 데이터가 없습니다\"를 반환하겠습니다.\\n\\n또한, JSON 데이터가 제공될 경우에는 각 필드를 아래와 같이 매핑하여 supabase에 입력하겠습니다.\\n- title → fieldValues3_Field_Value\\n- url (혹은 source) → fieldValues4_Field_Value\\n- summary → fieldValues5_Field_Value\\n- stock_code → fieldValues6_Field_Value\\n\\n따라서 입력된 데이터가 없거나 상장기업 뉴스가 없다는 내용(또는 관련 JSON)이 입력되지 않은 현재 상황에서는 다음과 같이 응답하겠습니다:\\n\\n2025.05.03 에는 데이터가 없습니다.'}\n",
      "수집 중: 2025.05.03 - 뉴스사 1020\n",
      "2025.05.03 1020 결과: {'output': '2025.05.03 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.02 - 뉴스사 1025\n",
      "2025.05.02 1025 결과: {'output': '2025.05.02 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.02 - 뉴스사 1020\n",
      "2025.05.02 1020 결과: {'output': 'success\\n\\n입력하신 뉴스 데이터가 정상적으로 등록되었습니다. (또는 이미 존재하는 데이터였습니다.)'}\n",
      "수집 중: 2025.05.01 - 뉴스사 1025\n",
      "2025.05.01 1025 결과: {'output': '안내해주신 내용 정리와 입력 매핑 기준은 다음과 같습니다.\\n\\n1. 입력 JSON이 없는 경우:  \\n   - \"2025.05.01 에는 데이터가 없습니다\" 반환\\n\\n2. 입력 JSON의 각 필드와 Supabase 필드 매핑:\\n   - title → fieldValues3_Field_Value\\n   - url → fieldValues4_Field_Value (source 테이블 필드와 매핑)\\n   - summery → fieldValues5_Field_Value (summary 테이블 필드와 매핑)\\n   - stock_code → fieldValues6_Field_Value (stock_cord 테이블 필드와 매핑)\\n\\n3. 주식 코드(stock_code)가 없는 뉴스는 무시하고 입력하지 않음\\n\\n4. 입력 처리 결과:\\n   - 정상 입력, 혹은 이미 동일 source가 있을 경우: success\\n   - 입력 실패 시: retry\\n\\n이제 입력 JSON을 전달해 주세요.'}\n",
      "수집 중: 2025.05.01 - 뉴스사 1020\n",
      "2025.05.01 1020 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.04.30 - 뉴스사 1025\n",
      "2025.04.30 1025 결과: {'output': '알겠습니다! 주어진 조건을 정리하면 다음과 같습니다.\\n\\n1. 입력받은 JSON이 없으면 \"2025.04.30 에는 데이터가 없습니다\"를 반환\\n2. JSON이 주어지면\\n    - 주어진 값을 Supabase의 테이블에 아래와 같이 매핑해 입력\\n        - title → fieldValues3_Field_Value\\n        - url → fieldValues4_Field_Value\\n        - summary → fieldValues5_Field_Value\\n        - stock_code → fieldValues6_Field_Value\\n    - 이미 동일한 source값(즉, url)이 있으면 그냥 \"success\" 반환(중복처리)\\n    - 실패시 \"retry\" 반환\\n    - 입력 데이터는 모두 상장기업이 없으므로 실제로는 입력되는 데이터가 없음(모두 필터링)\\n\\n추가로, JSON 입력 예시 또는 실제 데이터를 주시면 그에 따라 동작을 수행하겠습니다. 데이터가 없이 실행 요청하신 경우 설명대로 \"2025.04.30 에는 데이터가 없습니다\"를 바로 반환할 준비가 되어있습니다.\\n\\nJSON 데이터를 보내주시면 처리 가능합니다!'}\n",
      "수집 중: 2025.04.30 - 뉴스사 1020\n",
      "2025.04.30 1020 결과: {'output': '2025.04.30 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.29 - 뉴스사 1025\n",
      "2025.04.29 1025 결과: {'output': '2025.04.29 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.29 - 뉴스사 1020\n",
      "2025.04.29 1020 결과: {'output': '2025.04.29 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.28 - 뉴스사 1025\n",
      "2025.04.28 1025 결과: {'output': '안내해 주신 조건과 테이블 스키마, 매핑 규칙을 바탕으로 Supabase 입력 로직 및 대응 방안을 정리하면 다음과 같습니다.\\n\\n1. json이 주어지지 않으면:  \\n\\u2003→ \"2025.04.28 에는 데이터가 없습니다\" 반환\\n\\n2. 성공적으로 입력 시:  \\n\\u2003→ \"sucess\" 반환\\n\\n3. 실패 시:  \\n\\u2003→ \"retry\" 반환\\n\\n4. source(뉴스 URL)가 이미 DB에 있을 경우:  \\n\\u2003→ \"sucess\"만 반환\\n\\n5. 뉴스 데이터의 title, url, summary, stock_code 매핑:\\n- fieldValues3_Field_Value: title\\n- fieldValues4_Field_Value: url\\n- fieldValues5_Field_Value: summary\\n- fieldValues6_Field_Value: stock_code\\n\\n6. 상장기업 관련 뉴스 필터링 및 stock_code 매핑 불가 시:  \\n\\u2003→ \"모든 뉴스를 제공할 수 없습니다\" 안내\\n\\n필요한 json 데이터를 입력해 주시면 바로 처리하도록 하겠습니다.  \\n(json이 없으시면 위 규칙에 따라 안내 메시지를 보내드리겠습니다.)'}\n",
      "수집 중: 2025.04.28 - 뉴스사 1020\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.28 1020 결과: {}\n",
      "수집 중: 2025.04.27 - 뉴스사 1025\n",
      "2025.04.27 1025 결과: {'output': '2025.04.27 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.27 - 뉴스사 1020\n",
      "2025.04.27 1020 결과: {'output': '알겠습니다! 아래와 같은 규칙으로 Supabase에 데이터를 입력하겠습니다.\\n\\n- json(뉴스 데이터)을 주시면 입력을 시도하겠습니다.\\n- 만약 json이 없는 경우 \"2025.04.27 에는 데이터가 없습니다\"를 반환합니다.\\n- 이미 source(뉴스의 원본 url 등)가 DB에 있는 경우에도 성공 메시지(sucess)만 반환합니다.\\n- 입력 필드 매핑은 다음과 같이 하겠습니다:\\n    - title → fieldValues3_Field_Value\\n    - url(source) → fieldValues4_Field_Value\\n    - summary → fieldValues5_Field_Value\\n    - stock_code → fieldValues6_Field_Value\\n- 성공시 “sucess”, 실패시 “retry”를 반환하겠습니다.\\n\\n뉴스 json 데이터를 보내주세요!'}\n",
      "수집 중: 2025.04.26 - 뉴스사 1025\n",
      "2025.04.26 1025 결과: {'output': '알겠습니다! 아래와 같이 처리합니다.\\n\\n규칙 정리:\\n\\n- json 데이터가 주어지지 않으면 \"2025.04.26 에는 데이터가 없습니다\" 반환\\n- 입력 시 매핑은 다음과 같이:\\n    - title → fieldValues3_Field_Value\\n    - url → fieldValues4_Field_Value\\n    - summary → fieldValues5_Field_Value\\n    - stock_code → fieldValues6_Field_Value\\n- 성공적으로 입력하면 success, 문제 시 retry 반환\\n- primary key(source) 중복 시에도 success 반환\\n\\n만약 입력받으신 json 데이터를 주시면 바로 처리하겠습니다.\\n지금 데이터가 없으므로: 2025.04.26 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.26 - 뉴스사 1020\n",
      "2025.04.26 1020 결과: {'output': '네, 이해했습니다. 다음과 같이 처리하겠습니다.\\n\\n- 주어진 JSON이 없으면 \"2025.04.26 에는 데이터가 없습니다\"를 반환합니다.\\n- JSON이 주어지면, news_office, date, keyword, source가 모두 정상적으로 들어오는 경우에만\\n  - title → fieldValues3_Field_Value\\n  - url → fieldValues4_Field_Value (source를 url로 이해)\\n  - summary → fieldValues5_Field_Value\\n  - stock_code → fieldValues6_Field_Value (주어진 뉴스에서 상장기업 정보가 없으므로 null로 입력)\\n- 이미 동일한 source가 있을 경우도 success로 처리합니다.\\n- 데이터 입력 성공 시 success, 실패 시 retry를 반환합니다.\\n\\n뉴스에 상장기업과 무관함이 명시된 경우, stock_code는 비워서 처리합니다.\\n\\n이제 넣을 JSON 데이터를 보내주세요.'}\n",
      "수집 중: 2025.04.25 - 뉴스사 1025\n",
      "2025.04.25 1025 결과: {'output': '2025.04.25 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.25 - 뉴스사 1020\n",
      "2025.04.25 1020 결과: {'output': '네, 안내해주신 내용을 기반으로 아래와 같이 입력 규칙을 정리합니다.\\n\\n1. json 데이터가 주어지지 않으면 \"2025.04.25 에는 데이터가 없습니다\"를 반환합니다.\\n2. 데이터 입력 시, \\n\\u2003- 성공적으로 입력하거나 이미 동일한 source(=url)가 있을 때는 \"sucess\"를 반환합니다.\\n\\u2003- 실패 시에는 \"retry\"를 반환합니다.\\n3. 각 필드는 아래와 같이 매핑합니다:\\n\\u2003- fieldValues3_Field_Value <— title\\n\\u2003- fieldValues4_Field_Value <— url (source)\\n\\u2003- fieldValues5_Field_Value <— summary\\n\\u2003- fieldValues6_Field_Value <— stock_code\\n\\n또한, 마지막 문장에서처럼 주어진 뉴스가 상장기업과 관련이 없을 때는 따로 입력하지 않는 것으로 이해하겠습니다.\\n\\n뉴스 json 데이터를 제공해 주시면 입력을 진행하겠습니다.'}\n",
      "수집 중: 2025.04.24 - 뉴스사 1025\n",
      "2025.04.24 1025 결과: {'output': '2025.04.24 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.24 - 뉴스사 1020\n",
      "2025.04.24 1020 결과: {'output': 'sucess\\n\\n뉴스 데이터가 정상적으로 입력되었습니다. 입력값이 이미 존재해도 성공(success)으로 처리합니다. \\n\\n추가 문의 사항이 있다면 말씀해 주세요!'}\n",
      "수집 중: 2025.04.23 - 뉴스사 1025\n",
      "2025.04.23 1025 결과: {'output': '2025.04.23 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.23 - 뉴스사 1020\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.23 1020 결과: {}\n",
      "수집 중: 2025.04.22 - 뉴스사 1025\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.22 1025 결과: {}\n",
      "수집 중: 2025.04.22 - 뉴스사 1020\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.22 1020 결과: {}\n",
      "수집 중: 2025.04.21 - 뉴스사 1025\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# 시작 날짜 설정 (2025.06.30)\n",
    "current_date = datetime(2025, 6, 30)\n",
    "\n",
    "# 검색어와 뉴스사 리스트 설정\n",
    "query = \"사기\"\n",
    "news_offices = [\"1025\", \"1020\"] # 중앙일보, 동아일보\n",
    "\n",
    "# 과거로 이동하면서 데이터 수집\n",
    "while current_date.year >= 2025:  # 2025년까지 수집\n",
    "    \n",
    "    # 날짜 형식 변환 (YYYY.MM.DD)\n",
    "    date_str = current_date.strftime(\"%Y.%m.%d\")\n",
    "    \n",
    "    # 각 뉴스사별로 데이터 수집\n",
    "    for news_office in news_offices:\n",
    "        print(f\"수집 중: {date_str} - 뉴스사 {news_office}\")\n",
    "        \n",
    "        # API 호출 및 재시도 로직\n",
    "        max_retries = 3\n",
    "        retry_count = 0\n",
    "        \n",
    "        while retry_count < max_retries:\n",
    "            result = fetch_news_from_webhook(\n",
    "                query=query,\n",
    "                date=date_str,\n",
    "                news_office_checked=news_office\n",
    "            )\n",
    "            \n",
    "            # retry가 있으면 재시도\n",
    "            if result.get('retry'):\n",
    "                print(f\"재시도 {retry_count + 1}/{max_retries}\")\n",
    "                retry_count += 1\n",
    "                time.sleep(2)  # 재시도 전 2초 대기\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        # 결과 출력\n",
    "        print(f\"{date_str} {news_office} 결과: {result}\")\n",
    "        \n",
    "        # API 호출 간 간격 두기 \n",
    "        time.sleep(2)\n",
    "    \n",
    "    # 하루 전으로 이동\n",
    "    current_date -= timedelta(days=1)\n",
    "    \n",
    "print(\"데이터 수집 완료\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
