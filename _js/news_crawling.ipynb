{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from newspaper import Article\n",
    "\n",
    "# 🔍 네이버 뉴스 검색\n",
    "def search_naver_news_all(query, target_dates):\n",
    "    headers = {\n",
    "        \"X-Naver-Client-Id\": NAVER_CLIENT_ID,\n",
    "        \"X-Naver-Client-Secret\": NAVER_CLIENT_SECRET\n",
    "    }\n",
    "    all_filtered = []\n",
    "    for start in range(1, 500, 100):\n",
    "        params = {\n",
    "            \"query\": query,\n",
    "            \"display\": 100,\n",
    "            \"start\": start,\n",
    "            \"sort\": \"sim\"\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(\"https://openapi.naver.com/v1/search/news.json\", headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "        except:\n",
    "            break\n",
    "        items = response.json().get(\"items\", [])\n",
    "        for item in items:\n",
    "            try:\n",
    "                pubdate = parsedate_to_datetime(item[\"pubDate\"]).date()\n",
    "                if pubdate in target_dates:\n",
    "                    all_filtered.append(item[\"originallink\"].replace(\"amp;\", \"\"))\n",
    "            except:\n",
    "                continue\n",
    "    return all_filtered\n",
    "\n",
    "# 📄 기사 본문 추출\n",
    "def extract_article_text(url):\n",
    "    try:\n",
    "        article = Article(url, language=\"ko\")\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.text\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“이런 사기 꾼들에게 경제를 맡기겠느냐”고 했다. 그는 파업 노동자에 대한 기업의 손해배상 청구를 제한하는 노란봉투법(노동조합 및 노동관계조정법 개정안)을 예로 들며 “법을 어겨서 파업하는데 손해배상을 안 하면 이 나라가 무법천지가 되는 거 아니겠느냐”고 했다. 김 후보는 평택 삼성전자 반도체...\n"
     ]
    }
   ],
   "source": [
    "text = extract_article_text('https://search.naver.com/search.naver?where=news&query=%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90+%EC%82%AC%EA%B8%B0&sort=0&ds=2024.01.01&de=2025.06.01&nso=so%3Ar%2Cp%3Afrom20240101to20250601%2Ca%3A&start=1%20%EC%97%AC%EA%B8%B0%EC%84%9C%20%EB%89%B4%EC%8A%A4%20%EA%B0%80%EC%A0%B8%EC%99%80%EC%84%9C%20%EC%A0%95%EB%A6%AC%ED%95%B4%EC%A4%98')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_news_from_webhook(query: str, date: str, news_office_checked: str) -> dict:\n",
    "    \"\"\"n8n을 통해 supabase에 뉴스를 저장하는 함수\n",
    "    \n",
    "    Args:\n",
    "        query (str): 검색어\n",
    "        date (str): 날짜 (YYYY.MM.DD 형식)\n",
    "        news_office_checked (str): 뉴스사 ID\n",
    "          1023(조선일보)\n",
    "          1025(중앙일보)\n",
    "          1020(동아일보)\n",
    "          1015(한국경제)\n",
    "          1009(매일경제)\n",
    "          1011(서울경제)\n",
    "        \n",
    "    Returns:\n",
    "        dict: 응답 데이터\n",
    "          sucess : 성공했거나 이미 중복 데이터거나\n",
    "          retry : 실패 > 재시도\n",
    "    \"\"\"\n",
    "    url = \"https://moluvalu.app.n8n.cloud/webhook/3fc6b155-45d8-42cb-b54b-c81bd87ac445\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"date\": date,\n",
    "        \"news_office_checked\": news_office_checked\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"요청 중 오류가 발생했습니다: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수집 중: 2025.06.30 - 뉴스사 1015\n",
      "2025.06.30 1015 결과: {'output': '2025.06.30 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.30 - 뉴스사 1009\n",
      "2025.06.30 1009 결과: {'output': 'success'}\n",
      "수집 중: 2025.06.30 - 뉴스사 1011\n",
      "2025.06.30 1011 결과: {'output': 'success'}\n",
      "수집 중: 2025.06.29 - 뉴스사 1015\n",
      "2025.06.29 1015 결과: {'output': '네, 이해했습니다. 다음과 같이 작업을 처리하겠습니다.\\n\\n1. 입력받은 JSON이 없으면 \"2025.06.29 에는 데이터가 없습니다\"를 반환합니다.\\n2. 성공적으로 데이터 입력 시 success, 실패 시 retry를 반환합니다.\\n3. 이미 동일한 source(중복 URL)가 있으면 success만 반환합니다.\\n4. 각 컬럼 매핑도 명확히 적용합니다.\\n5. 미래에셋 주식코드는 매핑하지 않으며, 필터 지침도 반영하겠습니다.\\n\\n이제 입력할 JSON 데이터를 제공해주시면 저장 절차를 진행하겠습니다!'}\n",
      "수집 중: 2025.06.29 - 뉴스사 1009\n",
      "2025.06.29 1009 결과: {'output': 'sucess\\n\\n주어진 롯데케미칼 뉴스 데이터를 정상적으로 Supabase에 입력했습니다.'}\n",
      "수집 중: 2025.06.29 - 뉴스사 1011\n",
      "2025.06.29 1011 결과: {'output': '2025.06.29 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.28 - 뉴스사 1015\n",
      "2025.06.28 1015 결과: {'output': '\"2025.06.28 에는 데이터가 없습니다\"'}\n",
      "수집 중: 2025.06.28 - 뉴스사 1009\n",
      "2025.06.28 1009 결과: {'output': '2025.06.28 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.28 - 뉴스사 1011\n",
      "2025.06.28 1011 결과: {'output': 'sucess\\n\\n입력이 성공적으로 이루어졌습니다.'}\n",
      "수집 중: 2025.06.27 - 뉴스사 1015\n",
      "2025.06.27 1015 결과: {'output': '알겠습니다.\\n\\n입력하실 JSON 데이터가 주어지지 않았으므로, 조건에 따라 아래와 같이 반환합니다.\\n\\n2025.06.27 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.27 - 뉴스사 1009\n",
      "2025.06.27 1009 결과: {'output': 'success'}\n",
      "수집 중: 2025.06.27 - 뉴스사 1011\n",
      "2025.06.27 1011 결과: {'output': '2025.06.27 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.26 - 뉴스사 1015\n",
      "2025.06.26 1015 결과: {'output': '2025.06.26 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.26 - 뉴스사 1009\n",
      "2025.06.26 1009 결과: {'output': '2025.06.26 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.26 - 뉴스사 1011\n",
      "2025.06.26 1011 결과: {'output': '2025.06.26 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.25 - 뉴스사 1015\n",
      "2025.06.25 1015 결과: {'output': '2025.06.25 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.25 - 뉴스사 1009\n",
      "2025.06.25 1009 결과: {'output': '네, 입력 및 처리 기준 이해했습니다.\\n\\n아래와 같이 처리하겠습니다:\\n\\n- json 데이터가 주어지지 않으면 \"2025.06.25 에는 데이터가 없습니다\"를 반환\\n- 데이터가 있으면 지정한 필드를 테이블에 맞게 mapping하여 Supabase에 입력 시도\\n    - fieldValues3_Field_Value ⇨ title\\n    - fieldValues4_Field_Value ⇨ url\\n    - fieldValues5_Field_Value ⇨ summary\\n    - fieldValues6_Field_Value ⇨ stock_code\\n- 이미 동일한 source(중복) 데이터가 있어도 \"sucess\" 반환\\n- 실패 시엔 \"retry\" 반환\\n- 예시로 주신 뉴스들은 모두 적합한 기업 코드가 없어 입력하지 않음(즉 무시)\\n\\njson 데이터를 입력해 주시면 자동으로 처리하겠습니다.'}\n",
      "수집 중: 2025.06.25 - 뉴스사 1011\n",
      "2025.06.25 1011 결과: {'output': 'success'}\n",
      "수집 중: 2025.06.24 - 뉴스사 1015\n",
      "2025.06.24 1015 결과: {'output': '알겠습니다. 아래의 조건에 따라 작업을 진행합니다:\\n\\n- 입력되는 JSON 데이터가 없으면 \"2025.06.24 에는 데이터가 없습니다\"를 반환합니다.\\n- 데이터 입력이 성공할 경우 success, 실패 시 retry를 반환합니다.\\n- 이미 같은 source(즉, URL)가 존재해도 success를 반환합니다.\\n- 입력 파라미터 매핑:\\n  - title → fieldValues3_Field_Value\\n  - url → fieldValues4_Field_Value\\n  - summery → fieldValues5_Field_Value\\n  - stock_code → fieldValues6_Field_Value\\n- 종목코드를 찾을 수 없는 뉴스는 입력하지 않습니다.\\n\\nJSON 데이터를 주시면, 위 기준에 따라 Supabase에 입력처리하겠습니다. JSON을 입력해주세요!'}\n",
      "수집 중: 2025.06.24 - 뉴스사 1009\n",
      "2025.06.24 1009 결과: {'output': '2025.06.24 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.24 - 뉴스사 1011\n",
      "2025.06.24 1011 결과: {'output': '입력하실 json 데이터가 주어지지 않았습니다.\\n\\n2025.06.24 에는 데이터가 없습니다.'}\n",
      "수집 중: 2025.06.23 - 뉴스사 1015\n",
      "2025.06.23 1015 결과: {'output': '2025.06.23 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.23 - 뉴스사 1009\n",
      "2025.06.23 1009 결과: {'output': '2025.06.23 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.23 - 뉴스사 1011\n",
      "2025.06.23 1011 결과: {'output': '2025.06.23 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.22 - 뉴스사 1015\n",
      "2025.06.22 1015 결과: {'output': '2025.06.22 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.22 - 뉴스사 1009\n",
      "2025.06.22 1009 결과: {'output': 'retry\\n\\n(두 기사 모두 stock_code 필드를 null 또는 빈 문자열로 입력했기 때문에, 외래키 제약조건으로 인해 삽입 오류가 발생했습니다. stock_code가 비어 있을 경우 null로 저장하거나 해당 컬럼에 값을 입력하지 않도록 해야 정상 동작합니다.)'}\n",
      "수집 중: 2025.06.22 - 뉴스사 1011\n",
      "2025.06.22 1011 결과: {'output': '2025.06.22 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.21 - 뉴스사 1015\n",
      "2025.06.21 1015 결과: {'output': '뉴스 데이터를 입력해 주세요.  \\n뉴스 데이터가 json 형식으로 제공되어야 합니다.  \\n예시 형식:\\n```json\\n{\\n  \"title\": \"삼성전자 신제품 발표\",\\n  \"url\": \"https://news.example.com/article/1234\",\\n  \"summary\": \"삼성전자가 새로운 스마트폰을 공개했다.\",\\n  \"stock_code\": \"005930\"\\n}\\n```\\n뉴스 데이터를 입력하지 않을 경우, \"2025.06.21 에는 데이터가 없습니다\"라는 메시지를 반환합니다.  \\n입력해주시면 처리 결과를 안내해드리겠습니다.'}\n",
      "수집 중: 2025.06.21 - 뉴스사 1009\n",
      "2025.06.21 1009 결과: {'output': '입력하실 json 데이터가 없습니다.\\n\\n2025.06.21 에는 데이터가 없습니다\\n\\njson(뉴스 데이터)을 제공해주시면, 상장사 관련 내용 필터링 및 종목코드 매핑 작업을 도와드릴 수 있습니다.'}\n",
      "수집 중: 2025.06.21 - 뉴스사 1011\n",
      "2025.06.21 1011 결과: {'output': '알겠습니다! JSON 데이터를 입력해 주시면, 스키마와 매핑 기준에 따라 Supabase에 적절히 입력을 시도하겠습니다.\\n\\n만약 JSON이 주어지지 않으면, 아래와 같이 답변드릴 예정입니다:\\n\"2025.06.21 에는 데이터가 없습니다\"\\n\\n또한,\\n- 데이터 입력 성공 시: \"success\"\\n- 입력 실패 시: \"retry\"\\n- 이미 동일 source 데이터가 있더라도: \"success\"\\n\\n뉴스에 \"애플\", \"구글\", \"페이스북\" 관련 기사가 있어도 이들 기업의 상장 정보가 없으니, 이런 뉴스는 제외한다는 점도 인지했습니다. 상장 코드 등이 포함된 기업의 뉴스 데이터가 있다면 언제든 제공해 주세요!'}\n",
      "수집 중: 2025.06.20 - 뉴스사 1015\n",
      "2025.06.20 1015 결과: {'output': '알겠습니다.\\n\\n규칙 요약:\\n- json 데이터가 주어지지 않은 경우 ⇒ \"2025.06.20 에는 데이터가 없습니다\" 반환\\n- 데이터 삽입 성공 ⇒ \"sucess\" 반환 (동일한 source가 이미 있더라도 sucess)\\n- 데이터 삽입 실패 ⇒ \"retry\" 반환\\n- 매핑 규칙: title → fieldValues3_Field_Value, url → fieldValues4_Field_Value, summary → fieldValues5_Field_Value, stock_code → fieldValues6_Field_Value\\n- 주식코드가 없는 경우 데이터는 입력되지 않음\\n\\n뉴스 데이터의 기업명으로 주식코드를 찾을 수 없어 모든 항목을 버린다는 안내도 감사합니다.\\n\\n입력할 json 데이터를 주시면 위 기준에 따라 처리하겠습니다. (현재 json이 입력되지 않았으므로, \"2025.06.20 에는 데이터가 없습니다\"를 반환할 준비가 되어 있습니다.)'}\n",
      "수집 중: 2025.06.20 - 뉴스사 1009\n",
      "2025.06.20 1009 결과: {'output': '2025.06.20 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.20 - 뉴스사 1011\n",
      "2025.06.20 1011 결과: {'output': '네, 앞으로 입력하신 JSON 데이터를 다음 방식으로 처리하겠습니다.\\n\\n- 만약 JSON이 주어지지 않으면 “2025.06.20 에는 데이터가 없습니다”를 반환합니다.\\n- JSON이 정상적으로 주어졌을 때, 테이블 스키마에 맞춰 title, url, summary, stock_code를 각각 fieldValues3_Field_Value, fieldValues4_Field_Value, fieldValues5_Field_Value, fieldValues6_Field_Value에 매핑해 Supabase에 저장을 시도합니다.\\n- 이미 동일한 source(뉴스 원문 URL) 데이터가 테이블에 존재해도 성공(sucess)을 반환합니다.\\n- 입력이 정상적으로 완료되면 \"sucess\", 실패 시 \"retry\"를 반환합니다.\\n\\n상장기업 관련 주식코드 정보가 없는 경우에는 누락된 상태로 저장하며, 추후 추가 정보가 있다면 다시 제공해 주시면 됩니다.\\n\\n처리할 JSON 데이터를 입력해 주세요.'}\n",
      "수집 중: 2025.06.19 - 뉴스사 1015\n",
      "2025.06.19 1015 결과: {'output': '2025.06.19 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.19 - 뉴스사 1009\n",
      "2025.06.19 1009 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.06.19 - 뉴스사 1011\n",
      "2025.06.19 1011 결과: {'output': '2025.06.19 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.18 - 뉴스사 1015\n",
      "2025.06.18 1015 결과: {'output': '2025.06.18 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.18 - 뉴스사 1009\n",
      "2025.06.18 1009 결과: {'output': '2025.06.18 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.18 - 뉴스사 1011\n",
      "2025.06.18 1011 결과: {'output': '알겠습니다. 다음과 같이 동작하겠습니다.\\n\\n1. JSON 데이터가 입력되지 않으면 \"2025.06.18 에는 데이터가 없습니다\"를 반환합니다.\\n2. 정상적으로 입력이 완료되면 \"success\"를 반환하며, 만약 동일한 source(예: url)가 이미 있다면 중복 무시 후 \"success\"를 반환합니다.\\n3. 입력에 실패할 경우 \"retry\"를 반환합니다.\\n\\n필드 매핑 규칙:\\n\\n- fieldValues3_Field_Value: title\\n- fieldValues4_Field_Value: url\\n- fieldValues5_Field_Value: summary\\n- fieldValues6_Field_Value: stock_code\\n\\n이후 json 데이터를 제공해주시면, 바로 적절한 형식으로 supabase에 저장하거나 결과 메시지를 반환하겠습니다.'}\n",
      "수집 중: 2025.06.17 - 뉴스사 1015\n",
      "2025.06.17 1015 결과: {'output': '안내해주신 조건에 따라 수행 방식과 예외 상황에 대해 설명하겠습니다.\\n\\n현재, 입력하신 내용에서는 실제 뉴스 JSON 데이터가 주어지지 않았으므로 아래와 같이 결과를 반환합니다.\\n\\n출력:\\n2025.06.17 에는 데이터가 없습니다\\n\\n참고:\\n- 만약 JSON 데이터가 주어지면, 안내하신 필드에 따라 Supabase에 입력을 진행합니다.\\n- 종목 코드가 없는 상장 기업의 뉴스(예: 롯데건설)는 stock_code 값 없이 저장 시도하지만, 스키마에 따라 null이 허용되므로 저장 가능합니다. 단, 주어진 예에서는 종목 코드가 없으므로 해당 뉴스를 저장하지 않습니다.\\n- 동일 source의 데이터가 이미 있으면 성공(success)을 반환합니다. 실패할 경우 retry를 반환합니다.\\n\\n원하는 뉴스 JSON 데이터를 입력해주시면, 다시 입력 프로세스를 진행하겠습니다.'}\n",
      "수집 중: 2025.06.17 - 뉴스사 1009\n",
      "2025.06.17 1009 결과: {'output': '2025.06.17 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.17 - 뉴스사 1011\n",
      "2025.06.17 1011 결과: {'output': '알겠습니다. 주어진 조건에 따라 롯데건설과 관련된 뉴스는 상장 기업의 주식 코드를 찾을 수 없으므로, 해당 뉴스 데이터는 Supabase에 입력하지 않고 제외 처리됩니다. 따라서 추가로 처리할 데이터가 없습니다.\\n\\n이와 같이, 유효한 주식 코드가 없는 경우에는 입력 작업을 하지 않습니다. 추가적으로 입력할 JSON이 있으면 제공해 주세요. 입력 데이터가 없거나 조건에 맞지 않는 경우 안내 메시지를 반환하겠습니다.\\n\\n추가 데이터가 없다면 요청하신 대로 아래와 같이 응답합니다.\\n\"2025.06.17 에는 데이터가 없습니다\"'}\n",
      "수집 중: 2025.06.16 - 뉴스사 1015\n",
      "2025.06.16 1015 결과: {'output': '네, 안내해 주신 사항은 다음과 같이 정리됩니다:\\n\\n1. json이 입력되지 않으면 \"2025.06.16 에는 데이터가 없습니다\"를 반환  \\n2. 입력 성공 시 \"success\", 실패 시 \"retry\"를 반환  \\n3. source(=url)가 이미 있으면 \"success\"  \\n4. 뉴스 데이터에서 상장기업의 주식 코드(stock_code)를 찾지 못한 뉴스는 모두 제거(즉, stock_code 없는 데이터는 입력하지 않음)  \\n5. 매핑  \\n   - title → fieldValues3_Field_Value\\n   - url → fieldValues4_Field_Value\\n   - summary → fieldValues5_Field_Value\\n   - stock_code → fieldValues6_Field_Value\\n\\n뉴스 데이터(json)를 제공해 주시면 위 규칙에 맞게 입력(또는 적절히 메시지 반환) 처리하겠습니다.\\n\\n뉴스 json 데이터를 입력해 주세요.'}\n",
      "수집 중: 2025.06.16 - 뉴스사 1009\n",
      "2025.06.16 1009 결과: {'output': 'success'}\n",
      "수집 중: 2025.06.16 - 뉴스사 1011\n",
      "2025.06.16 1011 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.06.15 - 뉴스사 1015\n",
      "2025.06.15 1015 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.06.15 - 뉴스사 1009\n",
      "2025.06.15 1009 결과: {'output': '2025.06.15 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.15 - 뉴스사 1011\n",
      "2025.06.15 1011 결과: {'output': '2025.06.15 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.14 - 뉴스사 1015\n",
      "2025.06.14 1015 결과: {'output': '2025.06.14 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.14 - 뉴스사 1009\n",
      "2025.06.14 1009 결과: {'output': '2025.06.14 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.14 - 뉴스사 1011\n",
      "2025.06.14 1011 결과: {'output': '2025.06.14 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.13 - 뉴스사 1015\n",
      "2025.06.13 1015 결과: {'output': '2025.06.13 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.13 - 뉴스사 1009\n",
      "2025.06.13 1009 결과: {'output': '2025.06.13 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.13 - 뉴스사 1011\n",
      "2025.06.13 1011 결과: {'output': '2025.06.13 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.12 - 뉴스사 1015\n",
      "2025.06.12 1015 결과: {'output': '2025.06.12 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.12 - 뉴스사 1009\n",
      "2025.06.12 1009 결과: {'output': 'success'}\n",
      "수집 중: 2025.06.12 - 뉴스사 1011\n",
      "2025.06.12 1011 결과: {'output': '알겠습니다. 다음과 같이 처리하겠습니다.\\n\\n- 입력받은 JSON이 없으면 \"2025.06.12 에는 데이터가 없습니다\"를 반환합니다.\\n- JSON이 주어질 경우, title → fieldValues3_Field_Value, url → fieldValues4_Field_Value, summery → fieldValues5_Field_Value, stock_code → fieldValues6_Field_Value로 매핑해 Supabase에 입력을 시도합니다.\\n- 이미 동일한 source 데이터가 있어도 성공(sucess)만 반환합니다.\\n- 입력 시도 중 오류가 발생하면 retry를 반환합니다.\\n\\n단, 주어진 조건에 따라 상장기업과 직결된 뉴스를 식별하거나, 주식 코드를 찾을 수 없어 모든 뉴스를 필터링하여 버리도록 처리합니다.\\n\\n이제 입력받을 JSON을 전달해 주세요.'}\n",
      "수집 중: 2025.06.11 - 뉴스사 1015\n",
      "2025.06.11 1015 결과: {'output': '2025.06.11 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.11 - 뉴스사 1009\n",
      "2025.06.11 1009 결과: {'output': '2025.06.11 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.11 - 뉴스사 1011\n",
      "2025.06.11 1011 결과: {'output': '2025.06.11 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.10 - 뉴스사 1015\n",
      "2025.06.10 1015 결과: {'output': '2025.06.10 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.10 - 뉴스사 1009\n",
      "2025.06.10 1009 결과: {'output': '입력하신 내용을 바탕으로 데이터 입력 규칙을 다음과 같이 정리했습니다.\\n\\n- json 데이터가 없는 경우 \"2025.06.10 에는 데이터가 없습니다\" 반환\\n- 입력 성공 시 \"success\" 반환, 실패 시 \"retry\" 반환\\n- source(뉴스 원문 URL 등)가 이미 있다면 \"success\"만 반환(중복 허용: no error)\\n- 매핑 규칙\\n    - title → fieldValues3_Field_Value\\n    - url (혹은 source) → fieldValues4_Field_Value\\n    - summary(혹은 summery) → fieldValues5_Field_Value\\n    - stock_code(또는 stock_cord) → fieldValues6_Field_Value (모든 기업 주식 코드를 확정할 수 없는 경우 null 입력 허용)\\n\\n이제 json 데이터를 주시면, 위 기준에 따라 처리해드릴 수 있습니다.  \\n만약 json 데이터 없이 실행 요청하시면, “2025.06.10 에는 데이터가 없습니다” 라고 그대로 안내드릴 예정입니다.  \\njson 데이터를 입력해 주세요!'}\n",
      "수집 중: 2025.06.10 - 뉴스사 1011\n",
      "2025.06.10 1011 결과: {'output': '2025.06.10 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.09 - 뉴스사 1015\n",
      "2025.06.09 1015 결과: {'output': 'success\\n\\n(요청하신 데이터를 정상적으로 입력했습니다. 동일한 source가 이미 존재해도 역시 success만을 반환합니다.)'}\n",
      "수집 중: 2025.06.09 - 뉴스사 1009\n",
      "2025.06.09 1009 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.06.09 - 뉴스사 1011\n",
      "2025.06.09 1011 결과: {'output': '네, 입력 기준을 다음과 같이 이해했습니다.\\n\\n1. json이 없으면 \"2025.06.09 에는 데이터가 없습니다\"를 반환합니다.\\n2. json이 정상적으로 입력되면 success, 실패하면 retry를 반환합니다.\\n3. 중복 source(기존 DB에 이미 있는 source)여도 success만 반환합니다.\\n4. 각 입력 필드는 다음과 같이 매핑합니다:\\n   - fieldValues3_Field_Value → title\\n   - fieldValues4_Field_Value → url (source)\\n   - fieldValues5_Field_Value → summary\\n   - fieldValues6_Field_Value → stock_code\\n\\n상장기업 기사만 필터링하고 주식코드를 찾아 입력 작업을 시도하려 했으나, \"올리버생명과학\"과 \"크라운락자산운용\"의 주식 코드를 찾지 못했습니다. 따라서 뉴스 필터링 및 코드 입력 작업은 하지 않았습니다.\\n\\njson 입력을 주시면 해당 기준에 맞게 처리하겠습니다.'}\n",
      "수집 중: 2025.06.08 - 뉴스사 1015\n",
      "2025.06.08 1015 결과: {'output': '2025.06.08 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.08 - 뉴스사 1009\n",
      "2025.06.08 1009 결과: {'output': '2025.06.08 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.08 - 뉴스사 1011\n",
      "2025.06.08 1011 결과: {'output': '2025.06.08 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.07 - 뉴스사 1015\n",
      "2025.06.07 1015 결과: {'output': '요약하자면, 주어진 지침에 따라 뉴스 데이터(json)를 Supabase(raw_news_data 테이블)에 입력하기 전에, 뉴스가 상장기업과 관련되어 있고 종목코드(stock_code)가 있는 경우에만 입력해야 합니다. 현재는 \"모든 뉴스가 상장기업과 관련이 없거나 종목코드를 찾을 수 없습니다\", 즉 모든 뉴스를 제외(저장하지 않음)해야 함을 의미합니다.\\n\\n이 경우, 실제로 Supabase에 입력되는 데이터는 없으므로, 원하는 동작은 다음과 같습니다.\\n\\n- 만약 json이 없는 경우 → \"2025.06.07 에는 데이터가 없습니다\"\\n- json이 존재하더라도, 관련된 상장기업의 뉴스가 없으므로 아무것도 입력하지 않습니다 → \"success\"를 반환해야 합니다.\\n\\n테이블에 아무것도 입력하지 않는 특별한 상황에서, 추가적인 안내나 출력이 필요하다면 말씀해 주세요.  \\n실제 뉴스 데이터(json)를 입력해주시면, 해당 절차에 맞는 처리를 해드릴 수 있습니다.'}\n",
      "수집 중: 2025.06.07 - 뉴스사 1009\n",
      "2025.06.07 1009 결과: {'output': '2025.06.07 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.07 - 뉴스사 1011\n",
      "2025.06.07 1011 결과: {'output': '상장기업과 관련된 뉴스의 종목 코드(stock_code)를 찾을 수 없으므로, 모든 뉴스를 데이터베이스에 입력하지 않습니다. \\n즉, 입력할 데이터가 없습니다.\\n\\n만약 입력 JSON이 제공되지 않는다면 2025.06.07 에는 데이터가 없습니다를 반환해야 하며,\\n이번 요청에서는 입력할 JSON이 주어지지 않았으므로 다음과 같이 답변합니다.\\n\\n2025.06.07 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.06 - 뉴스사 1015\n",
      "2025.06.06 1015 결과: {'output': 'success\\n\\n데이터가 정상적으로 매핑 및 입력되었습니다. 동일 source(https://www.hankyung.com/article/202505306198r)가 이미 있는 경우에도 success만 반환합니다.'}\n",
      "수집 중: 2025.06.06 - 뉴스사 1009\n",
      "2025.06.06 1009 결과: {'output': '2025.06.06 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.06 - 뉴스사 1011\n",
      "2025.06.06 1011 결과: {'output': '2025.06.06 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.05 - 뉴스사 1015\n",
      "2025.06.05 1015 결과: {'output': '2025.06.05 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.05 - 뉴스사 1009\n",
      "2025.06.05 1009 결과: {'output': '2025.06.05 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.05 - 뉴스사 1011\n",
      "2025.06.05 1011 결과: {'output': '네, 안내해주신 내용을 정리하겠습니다.\\n\\n- 주어진 json이 없으면: \"2025.06.05 에는 데이터가 없습니다\"를 반환\\n- 입력 성공/중복 뉴스(source 동일): \"success\" 반환\\n- 입력 실패(재시도 필요): \"retry\" 반환\\n- 테이블에 저장 시 필드 매핑:\\n    - fieldValues3_Field_Value = title\\n    - fieldValues4_Field_Value = url\\n    - fieldValues5_Field_Value = summary\\n    - fieldValues6_Field_Value = stock_code (뉴스와 상장기업 매칭 시)\\n\\n뉴스 내 상장기업 식별정보가 없으면 필터링·정리가 불가능하므로 처리 불가로 간주합니다.\\n\\njson 데이터를 입력해주시면, 위 기준에 맞춰 Supabase에 저장하는 코드를 실행하겠습니다.'}\n",
      "수집 중: 2025.06.04 - 뉴스사 1015\n",
      "2025.06.04 1015 결과: {'output': '2025.06.04 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.04 - 뉴스사 1009\n",
      "2025.06.04 1009 결과: {'output': 'success\\n\\n(요청하신 상장기업 뉴스 2건이 정상적으로 입력되었습니다.)'}\n",
      "수집 중: 2025.06.04 - 뉴스사 1011\n",
      "2025.06.04 1011 결과: {'output': '2025.06.04 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.03 - 뉴스사 1015\n",
      "2025.06.03 1015 결과: {'output': '2025.06.03 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.03 - 뉴스사 1009\n",
      "2025.06.03 1009 결과: {'output': '2025.06.03 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.03 - 뉴스사 1011\n",
      "2025.06.03 1011 결과: {'output': '2025.06.03 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.02 - 뉴스사 1015\n",
      "2025.06.02 1015 결과: {'output': 'success\\n\\n해당 json 데이터를 Supabase에 성공적으로 입력하였습니다. 입력 요청에 중복 source 데이터가 있어도 \"success\"만을 반환합니다. 추가로 궁금한 점이 있으면 알려주세요.'}\n",
      "수집 중: 2025.06.02 - 뉴스사 1009\n",
      "2025.06.02 1009 결과: {'output': '네, 안내해주신 내용을 기준으로 다음과 같이 처리방식을 정리하겠습니다.\\n\\n처리 로직 요약:\\n\\n1. json 데이터가 입력되지 않을 경우:  \\n\\u2003반환값: \"2025.06.02 에는 데이터가 없습니다\"\\n\\n2. json 데이터가 주어질 경우:\\n    - 각 필드 매핑:\\n        - title → fieldValues3_Field_Value\\n        - url → fieldValues4_Field_Value\\n        - summary → fieldValues5_Field_Value\\n        - stock_code → fieldValues6_Field_Value\\n    - 데이터 삽입 시:\\n        - 성공: \"sucess\" 반환\\n        - 실패: \"retry\" 반환\\n        - 동일한 source 중복시에도: \"sucess\"만 반환\\n\\n3. “우리은행”의 주식 코드는 없으므로, 해당 기업 뉴스를 처리하지 않으며 안내 메시지 출력:\\n   업체명 \"우리은행\"에 대한 주식 코드를 찾을 수 없습니다. 관련 뉴스를 필터링 할 수 없습니다. 다른 상장기업 관련 뉴스를 찾거나 제공해 주시면 처리하겠습니다.\\n\\njson 데이터를 입력해주시면 위 방식에 따라 처리하겠습니다! json을 입력해주세요.'}\n",
      "수집 중: 2025.06.02 - 뉴스사 1011\n",
      "2025.06.02 1011 결과: {'output': '2025.06.02 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.01 - 뉴스사 1015\n",
      "2025.06.01 1015 결과: {'output': '2025.06.01 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.01 - 뉴스사 1009\n",
      "2025.06.01 1009 결과: {'output': '2025.06.01 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.06.01 - 뉴스사 1011\n",
      "2025.06.01 1011 결과: {'output': '2025.06.01 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.31 - 뉴스사 1015\n",
      "2025.05.31 1015 결과: {'output': '알겠습니다.\\n\\n안내해 드린대로, 이번 뉴스 데이터는 애플(Apple)과 관련되어 있지만, 주식 코드(stock_code) 정보를 찾을 수 없어 테이블에 입력에서 제외하겠습니다.\\n\\n만약 다른 뉴스 데이터가 있다면 해당 데이터를 제공해 주세요.  \\n또한, 만약 입력하실 JSON 데이터가 없다면 다음 요청에 대해 \"2025.05.31 에는 데이터가 없습니다\"를 반환하겠습니다.\\n\\n다른 뉴스가 있다면 JSON 형식으로 입력해 주세요!'}\n",
      "수집 중: 2025.05.31 - 뉴스사 1009\n",
      "2025.05.31 1009 결과: {'output': '2025.05.31 에는 데이터가 없습니다.'}\n",
      "수집 중: 2025.05.31 - 뉴스사 1011\n",
      "2025.05.31 1011 결과: {'output': '해당 뉴스가 상장기업과 무관하거나 주식 코드(stock_code) 정보를 찾을 수 없어 필터링(즉, 저장하지 않음)합니다. 따라서, 입력을 진행하지 않습니다.\\n\\n추가로, 만약 입력 데이터를 받지 못했다면 요청하신 대로 다음과 같이 반환합니다:\\n\\n2025.05.31 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.30 - 뉴스사 1015\n",
      "2025.05.30 1015 결과: {'output': 'success\\n\\n- 입력한 데이터 (2025.05.30, 하이브 관련 기사)는 성공적으로 처리되었습니다.\\n- 이미 동일한 source(https://www.hankyung.com/article/2025052950331)가 있어도 success만 반환합니다.'}\n",
      "수집 중: 2025.05.30 - 뉴스사 1009\n",
      "2025.05.30 1009 결과: {'output': 'sucess\\n\\n해당 json 데이터가 정상적으로 입력(또는 이미 존재)하여 성공적으로 처리되었습니다.'}\n",
      "수집 중: 2025.05.30 - 뉴스사 1011\n",
      "2025.05.30 1011 결과: {'output': '2025.05.30 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.29 - 뉴스사 1015\n",
      "2025.05.29 1015 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.05.29 - 뉴스사 1009\n",
      "2025.05.29 1009 결과: {'output': 'success\\n\\n(입력요구 사항 대로 정상 입력되었습니다. 동일한 source가 이미 존재해도 success만 반환합니다.)'}\n",
      "수집 중: 2025.05.29 - 뉴스사 1011\n",
      "2025.05.29 1011 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.28 - 뉴스사 1015\n",
      "2025.05.28 1015 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.05.28 - 뉴스사 1009\n",
      "2025.05.28 1009 결과: {'output': 'sucess\\n\\n(데이터가 정상적으로 입력되었거나 이미 존재하는 source는 중복입력 없이 성공 처리되었습니다.)'}\n",
      "수집 중: 2025.05.28 - 뉴스사 1011\n",
      "2025.05.28 1011 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.27 - 뉴스사 1015\n",
      "2025.05.27 1015 결과: {'output': '2025.05.27 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.27 - 뉴스사 1009\n",
      "2025.05.27 1009 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.27 - 뉴스사 1011\n",
      "2025.05.27 1011 결과: {'output': '2025.05.27 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.26 - 뉴스사 1015\n",
      "2025.05.26 1015 결과: {'output': '2025.05.26 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.26 - 뉴스사 1009\n",
      "2025.05.26 1009 결과: {'output': '2025.05.26 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.26 - 뉴스사 1011\n",
      "2025.05.26 1011 결과: {'output': '2025.05.26 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.25 - 뉴스사 1015\n",
      "2025.05.25 1015 결과: {'output': '알겠습니다! 아래 안내에 따라 진행하겠습니다.\\n\\n작업 방식 안내:\\n\\n- 입력받은 json 데이터가 없으면: \"2025.05.25 에는 데이터가 없습니다\"라는 메시지를 반환합니다.\\n- json이 있을 경우, 적절히 파싱하여 Supabase에 입력을 시도합니다.\\n  - 이미 동일한 source(즉, url)가 있더라도 성공 메시지(\"success\")만 반환합니다.\\n  - 입력에 실패하면 \"retry\"를 반환합니다.\\n\\n뉴스를 기반으로 관련 상장 기업(stock_code)을 식별해야 하며, 이를 위해 기업명이 json 내에 명시되어 있거나 별도로 입력되어야 합니다.\\n\\n진행 방법:\\n\\n- json 데이터를 제공해주십시오.\\n- json 내에 title, url, summary, stock_code 필드가 있어야 합니다.\\n- 여러 건의 뉴스 데이터가 있으면 배열 형태로 보내주셔도 됩니다.\\n\\n예시 입력 형식:\\n```json\\n{\\n  \"title\": \"삼성전자, 신제품 출시\",\\n  \"url\": \"https://news.example.com/123\",\\n  \"summary\": \"삼성전자가 새로운 스마트폰을 출시했다.\",\\n  \"stock_code\": \"005930\"\\n}\\n```\\n\\n또는 여러 건을 배열로:\\n```json\\n[\\n  {\\n    \"title\": \"삼성전자, 신제품 출시\",\\n    \"url\": \"https://news.example.com/123\",\\n    \"summary\": \"삼성전자가 새로운 스마트폰을 출시했다.\",\\n    \"stock_code\": \"005930\"\\n  },\\n  {\\n    \"title\": \"네이버, AI 챗봇 공개\",\\n    \"url\": \"https://news.example.com/456\",\\n    \"summary\": \"네이버가 최신 AI 챗봇을 선보였다.\",\\n    \"stock_code\": \"035420\"\\n  }\\n]\\n```\\n\\n이제 입력하실 뉴스를 JSON 형식으로 보내주시면, 즉시 처리하겠습니다.'}\n",
      "수집 중: 2025.05.25 - 뉴스사 1009\n",
      "2025.05.25 1009 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.25 - 뉴스사 1011\n",
      "2025.05.25 1011 결과: {'output': '2025.05.25 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.24 - 뉴스사 1015\n",
      "2025.05.24 1015 결과: {'output': '2025.05.24 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.24 - 뉴스사 1009\n",
      "2025.05.24 1009 결과: {'output': '알겠습니다. 입력받을 JSON 데이터에 다음과 같이 대응하여 Supabase에 저장하겠습니다.\\n\\n- JSON이 없으면: \"2025.05.24 에는 데이터가 없습니다\"를 반환\\n- 성공적으로 입력 또는 이미 source가 있으면: sucess 반환\\n- 실패 시: retry 반환\\n\\n테이블 컬럼과 매핑:\\n- title → fieldValues3_Field_Value\\n- url → fieldValues4_Field_Value (source에 해당)\\n- summary → fieldValues5_Field_Value\\n- stock_code → fieldValues6_Field_Value\\n\\n또한, 뉴스가 상장기업과 관련된 경우에만 처리될 수 있도록 적절한 정보를 활용하겠습니다.\\n\\n뉴스 JSON 데이터를 입력해주시면, 요청하신대로 처리하겠습니다. JSON 데이터를 보내주세요!'}\n",
      "수집 중: 2025.05.24 - 뉴스사 1011\n",
      "2025.05.24 1011 결과: {'output': '안내해 주신 절차를 적용해 요약합니다.\\n\\n1. JSON 입력이 없는 경우 \"2025.05.24 에는 데이터가 없습니다\"를 반환합니다.\\n2. JSON 입력이 있으면, 뉴스 제목/요약에서 상장기업명을 매칭해 관련 뉴스만 필터링합니다.\\n3. 관련 뉴스에 대해 기업명을 기반으로 종목코드(stock_code)를 찾습니다.\\n4. Supabase 테이블에 아래와 같이 필드 맵핑하여 입력합니다:\\n   - fieldValues3_Field_Value: title\\n   - fieldValues4_Field_Value: url (source로 해석)\\n   - fieldValues5_Field_Value: summary\\n   - fieldValues6_Field_Value: stock_code\\n5. 이미 동일한 source(=url)가 있거나, 입력에 성공하면 \"sucess\" 를, 실패하면 \"retry\"를 반환합니다.\\n\\n진행을 위해 뉴스 데이터(JSON)와 상장기업 목록(기업명, stock_code 정보를 포함)이 필요합니다.  \\nCSV, JSON 등으로 상장기업 정보를 제공해 주시면 뉴스 데이터에서 기업명을 정확히 식별하고, 종목코드를 자동 매핑할 수 있습니다.\\n\\n뉴스 데이터와(필요시) 상장기업 리스트를 제공해 주시면 바로 실행하겠습니다.'}\n",
      "수집 중: 2025.05.23 - 뉴스사 1015\n",
      "2025.05.23 1015 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.23 - 뉴스사 1009\n",
      "2025.05.23 1009 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.23 - 뉴스사 1011\n",
      "2025.05.23 1011 결과: {'output': '2025.05.23 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.22 - 뉴스사 1015\n",
      "2025.05.22 1015 결과: {'output': '네, 안내해주신 내용 잘 이해했습니다.\\n\\n요약하자면:\\n\\n- JSON이 주어지지 않을 경우 → \"2025.05.22 에는 데이터가 없습니다\" 반환\\n- 정상적으로 입력 시 → success 반환\\n- 실패 시 → retry 반환\\n- 이미 동일한 source(뉴스 URL 등)가 있더라도 → success 반환\\n\\nSupabase에 입력하는 매핑 기준:\\n\\n- title → fieldValues3_Field_Value\\n- url(source 등) → fieldValues4_Field_Value\\n- summary → fieldValues5_Field_Value\\n- stock_code(종목코드) → fieldValues6_Field_Value\\n\\n그리고 상장기업에 관련된 뉴스만 필터링하여, 종목코드를 찾을 수 없는 경우는 JSON을 생성하지 않습니다.\\n\\n앞으로 뉴스 JSON 데이터를 주시면 위 기준에 맞춰 입력하도록 하겠습니다. 준비되셨으면 JSON 데이터를 제공해주세요!'}\n",
      "수집 중: 2025.05.22 - 뉴스사 1009\n",
      "2025.05.22 1009 결과: {'output': 'success\\n\\n해당 데이터를 기준대로 정상적으로 입력했습니다. (혹시 동일한 source가 이미 있어도, 성공 처리됩니다.)\\n\\n추가적으로 궁금한 점이 있으면 말씀해 주세요!'}\n",
      "수집 중: 2025.05.22 - 뉴스사 1011\n",
      "2025.05.22 1011 결과: {'output': 'sucess\\n\\n(입력받은 두 건의 데이터 모두 정상적으로 저장 혹은 이미 존재하는 데이터로 처리되었습니다.)'}\n",
      "수집 중: 2025.05.21 - 뉴스사 1015\n",
      "2025.05.21 1015 결과: {'output': '2025.05.21 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.21 - 뉴스사 1009\n",
      "2025.05.21 1009 결과: {'output': 'sucess\\n\\n※ 다음 뉴스에서는 상장 기업의 종목 코드를 찾을 수 없었습니다.\\n- \"수백억 판매대금 떼먹고 영업종료...‘제2의 티메프’ 알렛츠 대표 검찰...\"'}\n",
      "수집 중: 2025.05.21 - 뉴스사 1011\n",
      "2025.05.21 1011 결과: {'output': '2025.05.21 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.20 - 뉴스사 1015\n",
      "2025.05.20 1015 결과: {'output': '2025.05.20 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.20 - 뉴스사 1009\n",
      "2025.05.20 1009 결과: {'output': '2025.05.20 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.20 - 뉴스사 1011\n",
      "2025.05.20 1011 결과: {'output': '2025.05.20 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.19 - 뉴스사 1015\n",
      "2025.05.19 1015 결과: {'output': '2025.05.19 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.19 - 뉴스사 1009\n",
      "2025.05.19 1009 결과: {'output': 'sucess\\n\\n데이터가 정상적으로 입력되었습니다. (동일 source가 이미 존재해도 성공만 반환)'}\n",
      "수집 중: 2025.05.19 - 뉴스사 1011\n",
      "2025.05.19 1011 결과: {'output': '2025.05.19 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.18 - 뉴스사 1015\n",
      "2025.05.18 1015 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.18 - 뉴스사 1009\n",
      "2025.05.18 1009 결과: {'output': '2025.05.18 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.18 - 뉴스사 1011\n",
      "2025.05.18 1011 결과: {'output': '2025.05.18 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.17 - 뉴스사 1015\n",
      "2025.05.17 1015 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.05.17 - 뉴스사 1009\n",
      "2025.05.17 1009 결과: {'output': '2025.05.17 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.17 - 뉴스사 1011\n",
      "2025.05.17 1011 결과: {'output': '2025.05.17 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.16 - 뉴스사 1015\n",
      "2025.05.16 1015 결과: {'output': '2025.05.16 에는 데이터가 없습니다.'}\n",
      "수집 중: 2025.05.16 - 뉴스사 1009\n",
      "2025.05.16 1009 결과: {'output': '네, 안내해주신 조건에 따라 Supabase에 데이터를 입력하거나, 조건에 맞게 응답을 반환하는 처리를 할 수 있습니다.\\n\\n정리:\\n- 입력받은 json(뉴스)이 없으면: \"2025.05.16 에는 데이터가 없습니다\" 반환\\n- 입력(json)이 있으면:\\n    - 테이블 스키마에 맞춰 title→fieldValues3_Field_Value, url→fieldValues4_Field_Value, summary→fieldValues5_Field_Value, stock_code→fieldValues6_Field_Value 매핑\\n    - 이미 같은 source(아마 url을 의미하는 듯)가 있으면 중복 허용, 성공(sucess) 반환\\n    - 입력/저장 실패시 retry 반환\\n\\n\"물고기뮤직\"과 \"롯데엔터테인먼트\"는 주식코드(상장사 코드)를 찾지 못해 stock_code는 null로 입력하신다는 이해도 맞습니다.\\n\\n준비가 됐으니, json 데이터를 주시면 바로 입력을 도와드리겠습니다.'}\n",
      "수집 중: 2025.05.16 - 뉴스사 1011\n",
      "2025.05.16 1011 결과: {'output': '\"2025.05.16 에는 데이터가 없습니다\"'}\n",
      "수집 중: 2025.05.15 - 뉴스사 1015\n",
      "2025.05.15 1015 결과: {'output': '2025.05.15 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.15 - 뉴스사 1009\n",
      "2025.05.15 1009 결과: {'output': '2025.05.15 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.15 - 뉴스사 1011\n",
      "2025.05.15 1011 결과: {'output': '2025.05.15 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.14 - 뉴스사 1015\n",
      "2025.05.14 1015 결과: {'output': '2025.05.14 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.14 - 뉴스사 1009\n",
      "2025.05.14 1009 결과: {'output': '입력하신 설명과 조건에 따라 처리 방식을 정리하겠습니다.\\n\\n1. json 데이터가 없으면 \"2025.05.14 에는 데이터가 없습니다\"를 반환\\n2. 정상적으로 입력 시 sucess, 실패 시 retry 반환\\n3. 같은 source(중복) 데이터여도 sucess 반환\\n4. 매핑은 아래와 같이 함:\\n   - title → fieldValues3_Field_Value\\n   - url → fieldValues4_Field_Value (설명상 source=text인데 url로 받도록 명시)\\n   - summary → fieldValues5_Field_Value\\n   - stock_code → fieldValues6_Field_Value\\n\\n이제 json 데이터를 올려주시면 자동으로 적절한 처리를 시도하겠습니다. 데이터를 입력해주세요!'}\n",
      "수집 중: 2025.05.14 - 뉴스사 1011\n",
      "2025.05.14 1011 결과: {'output': '알겠습니다. 아래와 같이 처리하겠습니다.\\n\\n조건 정리\\n\\n1. json 데이터가 주어지지 않으면 \"2025.05.14 에는 데이터가 없습니다\"를 반환합니다.\\n2. 입력 성공 시 sucess, 실패 시 retry 반환합니다.\\n3. 중복 source 데이터인 경우도 sucess 반환합니다.\\n4. 각 필드 매핑은 다음과 같습니다:\\n\\n- title → fieldValues3_Field_Value\\n- url(source) → fieldValues4_Field_Value\\n- summery → fieldValues5_Field_Value\\n- stock_code → fieldValues6_Field_Value\\n\\n우리은행 뉴스가 상장기업 관련이지만 주식 코드가 없으므로, 상장기업 관련 뉴스 및 주식 코드는 반환하지 않습니다.\\n\\njson 데이터를 입력해 주시면 처리하겠습니다.'}\n",
      "수집 중: 2025.05.13 - 뉴스사 1015\n",
      "2025.05.13 1015 결과: {'output': '안내 감사합니다. 이후 json 데이터가 주어지면 다음과 같이 처리하겠습니다.\\n\\n- json이 주어지지 않을 시:  \\n\"2025.05.13 에는 데이터가 없습니다\"를 반환\\n\\n- 데이터가 있을 시:\\n    - 성공적으로 삽입되면 \"sucess\" 반환\\n    - 실패 시 \"retry\" 반환\\n    - 이미 동일한 source 데이터 존재 시에도 \"sucess\" 반환\\n\\n매핑 방식:\\n- title → fieldValues3_Field_Value\\n- url → fieldValues4_Field_Value\\n- summary → fieldValues5_Field_Value\\n- stock_code → fieldValues6_Field_Value\\n\\n또한, 주어진 뉴스가 모두 상장기업과 관련이 없어 주식 코드가 없는 경우라면 입력하지 않고 필터링 된 것으로 간주하겠습니다.\\n\\njson 데이터를 입력해주세요.'}\n",
      "수집 중: 2025.05.13 - 뉴스사 1009\n",
      "2025.05.13 1009 결과: {'output': '2025.05.13 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.13 - 뉴스사 1011\n",
      "2025.05.13 1011 결과: {'output': '알겠습니다. 주어진 조건에 따라 동작하겠습니다.\\n\\n- JSON 데이터가 주어지지 않을 경우: \"2025.05.13 에는 데이터가 없습니다\"를 반환\\n- 성공적으로 입력 시: sucess 반환\\n- 실패 시: retry 반환\\n- 동일한 source가 이미 있을 때도 sucess 반환\\n\\n필드 매핑:\\n- title → fieldValues3_Field_Value\\n- url → fieldValues4_Field_Value\\n- summery → fieldValues5_Field_Value\\n- stock_code → fieldValues6_Field_Value\\n\\n입력 데이터에 회사명 및 관련 주식 코드가 없으므로, 해당 데이터가 없을 때는 별도 응답 없이 대기합니다.\\n\\n이제 JSON 데이터를 주시면, 위 규칙에 맞춰 Supabase에 입력을 시도하겠습니다. JSON을 보내주세요.'}\n",
      "수집 중: 2025.05.12 - 뉴스사 1015\n",
      "2025.05.12 1015 결과: {'output': '네, 이해했습니다. 다음과 같이 처리하겠습니다.\\n\\n- JSON이 주어지지 않으면 \"2025.05.12 에는 데이터가 없습니다\"를 반환합니다.\\n- JSON이 주어지면, 테이블의 스키마에 맞게 입력을 시도합니다.\\n- 입력이 성공하거나 이미 동일한 source(중복) 데이터가 있어도 \"success\"를 반환합니다.\\n- 입력에 실패하면(기타 오류) \"retry\"를 반환합니다.\\n- 필드 매핑은 다음과 같이 처리합니다:\\n    - fieldValues3_Field_Value: title\\n    - fieldValues4_Field_Value: url\\n    - fieldValues5_Field_Value: summery (summary)\\n    - fieldValues6_Field_Value: stock_code\\n\\nJSON 데이터를 제공해 주시면 요청하신 대로 처리해드리겠습니다.'}\n",
      "수집 중: 2025.05.12 - 뉴스사 1009\n",
      "2025.05.12 1009 결과: {'output': '안내해주신 기준을 정리하면 다음과 같습니다.\\n\\n1. 입력받을 JSON이 없으면 \"2025.05.12 에는 데이터가 없습니다\"를 반환\\n2. Supabase 테이블에 입력(뉴스 데이터 1건) 시,\\n   - 성공하면 success를 반환\\n   - 실패하면 retry를 반환\\n   - 이미 동일한 source(중복 URL)가 있으면 success만 반환\\n3. 매핑 방식(키 이름 기준)\\n   - title → fieldValues3_Field_Value\\n   - url → fieldValues4_Field_Value (source는 url로 간주)\\n   - summery → fieldValues5_Field_Value (오타는 summary지만, summery로 안내 주심)\\n   - stock_code → fieldValues6_Field_Value\\n\\n뉴스 데이터에 관련 상장기업이 없다면 stock_code는 공란이어도 필터링하지 않음(즉, 많이 비어 있을 수 있음).\\n\\n이제 JSON 데이터를 입력해주시면, 안내해주신 규칙에 따라 Supabase에 적절히 입력 작업을 시도하겠습니다.'}\n",
      "수집 중: 2025.05.12 - 뉴스사 1011\n",
      "2025.05.12 1011 결과: {'output': '2025.05.12 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.11 - 뉴스사 1015\n",
      "2025.05.11 1015 결과: {'output': '알겠습니다. 주어진 조건에 따라 동작하도록 설정하겠습니다.\\n\\n- 만약 입력받는 json 데이터가 없으면 \"2025.05.11 에는 데이터가 없습니다\"를 반환합니다.\\n- 데이터 입력에 성공하면 sucess, 실패하면 retry를 반환합니다.\\n- 이미 동일한 source(=url) 값이 존재해도 성공(sucess)만을 반환합니다.\\n- 각 필드에 아래와 같이 매핑합니다:\\n    - fieldValues3_Field_Value: title\\n    - fieldValues4_Field_Value: url\\n    - fieldValues5_Field_Value: summary\\n    - fieldValues6_Field_Value: stock_code (없다면 null)\\n\\n준비가 완료되었습니다. json 데이터를 입력해 주세요.'}\n",
      "수집 중: 2025.05.11 - 뉴스사 1009\n",
      "2025.05.11 1009 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.11 - 뉴스사 1011\n",
      "2025.05.11 1011 결과: {'output': '알겠습니다! 아래의 원칙에 따라 json 데이터를 Supabase에 입력하겠습니다.\\n\\n1. json이 주어지지 않을 시: “2025.05.11 에는 데이터가 없습니다” 반환\\n2. 성공시: success\\n3. 실패시: retry\\n4. source가 이미 있으면: success\\n5. 필드 매핑:\\n    - title → fieldValues3_Field_Value\\n    - url → fieldValues4_Field_Value\\n    - summery → fieldValues5_Field_Value\\n    - stock_code → fieldValues6_Field_Value\\n\\n또한, 뉴스가 상장사와 관련 없고 예를 들어 “유재환” 등 개인에 관한 것이라면 필터링(입력하지 않음)합니다.\\n\\njson을 제공해주시면 해당 절차에 맞추어 처리하겠습니다.'}\n",
      "수집 중: 2025.05.10 - 뉴스사 1015\n",
      "2025.05.10 1015 결과: {'output': '2025.05.10 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.10 - 뉴스사 1009\n",
      "2025.05.10 1009 결과: {'output': '2025.05.10 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.10 - 뉴스사 1011\n",
      "2025.05.10 1011 결과: {'output': '알겠습니다! 이제 json 데이터를 입력해 주세요. \\n\\n- 만약 json 데이터가 주어지지 않으면 \"2025.05.10 에는 데이터가 없습니다\"를 반환하겠습니다.\\n- json 데이터가 주어지면 스키마에 맞춰 입력을 시도하고, 성공 시 success, 실패 시 retry를 반환하겠습니다.\\n- 동의어 source(즉, 동일 url)가 이미 있으면 그냥 success만 반환하겠습니다.\\n\\n지금 입력하실 json 데이터를 보내주세요!'}\n",
      "수집 중: 2025.05.09 - 뉴스사 1015\n",
      "2025.05.09 1015 결과: {'output': '2025.05.09 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.09 - 뉴스사 1009\n",
      "2025.05.09 1009 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.09 - 뉴스사 1011\n",
      "2025.05.09 1011 결과: {'output': '2025.05.09 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.08 - 뉴스사 1015\n",
      "2025.05.08 1015 결과: {'output': '2025.05.08 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.08 - 뉴스사 1009\n",
      "2025.05.08 1009 결과: {'output': '2025.05.08 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.08 - 뉴스사 1011\n",
      "2025.05.08 1011 결과: {'output': '2025.05.08 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.07 - 뉴스사 1015\n",
      "2025.05.07 1015 결과: {'output': 'sucess\\n\\n(동일한 source 데이터가 이미 존재하더라도 sucess만 반환합니다. 5건 중 1건만 실제로 입력되었으며, 나머지는 이미 존재하는 데이터로 판단되어 성공 처리합니다.)'}\n",
      "수집 중: 2025.05.07 - 뉴스사 1009\n",
      "2025.05.07 1009 결과: {'output': '2025.05.07 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.07 - 뉴스사 1011\n",
      "2025.05.07 1011 결과: {'output': '알겠습니다. 아래와 같이 입력 정책을 정리합니다:\\n\\n정책 및 입력 매핑\\n\\n1. json 데이터가 없는 경우: \"2025.05.07 에는 데이터가 없습니다\" 반환\\n2. 성공 시: \"sucess\" 반환  \\n   실패 시: \"retry\" 반환\\n   (동일 source가 이미 있어도 \"sucess\"만 반환)\\n3. 입력 매핑\\n\\n- fieldValues3_Field_Value ← title  \\n- fieldValues4_Field_Value ← url  \\n- fieldValues5_Field_Value ← summery  \\n- fieldValues6_Field_Value ← stock_code\\n\\n상장기업 관련 뉴스 필터링 결과\\n\\n제공된 모든 뉴스에서 상장기업 관련 종목코드를 찾지 못했으므로, 이 데이터에선 raw_news_data 테이블에 입력할 상장기업 관련 뉴스가 없습니다.\\n\\n다음 중 하나를 입력하실 수 있습니다:\\n\\n- supabase에 입력할 json 데이터\\n- 아니면 신규 데이터가 없는 경우 위 정책에 따라 안내\\n\\n뉴스 json이 준비되면 다시 입력해 주세요!'}\n",
      "수집 중: 2025.05.06 - 뉴스사 1015\n",
      "2025.05.06 1015 결과: {'output': '2025.05.06 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.06 - 뉴스사 1009\n",
      "2025.05.06 1009 결과: {'output': '2025.05.06 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.06 - 뉴스사 1011\n",
      "2025.05.06 1011 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.05 - 뉴스사 1015\n",
      "2025.05.05 1015 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.05 - 뉴스사 1009\n",
      "2025.05.05 1009 결과: {'output': 'success'}\n",
      "수집 중: 2025.05.05 - 뉴스사 1011\n",
      "2025.05.05 1011 결과: {'output': '네, 이해했습니다. 입력받은 JSON을 다음과 같이 Supabase에 저장하겠습니다.\\n\\n- json이 주어지지 않으면 \"2025.05.05 에는 데이터가 없습니다\"를 반환\\n- 저장에 성공하면 success, 실패하면 retry, 이미 source가 존재해도 success\\n- 매핑: title → fieldValues3_Field_Value, url → fieldValues4_Field_Value, summary → fieldValues5_Field_Value, stock_code → fieldValues6_Field_Value\\n\\n뉴스의 요약만으로 상장기업 관련 뉴스를 정확하게 선별하려면 추가 정보(기업명 등)가 필요합니다. 앞으로 구체적인 기업명(또는 코드)이 뉴스에 포함되어 있다면, 상장 여부를 필터링 후 입력해드릴 수 있습니다.\\n\\n뉴스 JSON을 입력해주시면 처리를 시작하겠습니다.'}\n",
      "수집 중: 2025.05.04 - 뉴스사 1015\n",
      "2025.05.04 1015 결과: {'output': '2025.05.04 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.04 - 뉴스사 1009\n",
      "2025.05.04 1009 결과: {'output': '2025.05.04 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.04 - 뉴스사 1011\n",
      "2025.05.04 1011 결과: {'output': '알겠습니다. 제공하신 조건에 따라 동작 방식을 정리하면 아래와 같습니다.\\n\\n- 만약 json이 주어지지 않으면 \"2025.05.04 에는 데이터가 없습니다\"를 반환합니다.\\n- 정상적으로 입력이 이루어지면 \"success\"를, 실패시 \"retry\"를 반환합니다.\\n- 이미 동일한 source(뉴스 URL 혹은 고유값)가 있어도 \"success\"만 반환합니다.\\n- 필드 매핑은 아래와 같습니다:\\n    - title → fieldValues3_Field_Value\\n    - url → fieldValues4_Field_Value\\n    - summary → fieldValues5_Field_Value\\n    - stock_code → fieldValues6_Field_Value\\n- 뉴스에서 언급된 기업 중 두나무는 상장기업이 아니므로 모든 뉴스를 제외 처리합니다.\\n\\n입력하실 JSON 데이터를 제공해주시면, 조건에 맞추어 Supabase에 바로 입력하는 처리를 도와드리겠습니다.\\n\\n지금 JSON 데이터를 입력해주시기 바랍니다.'}\n",
      "수집 중: 2025.05.03 - 뉴스사 1015\n",
      "2025.05.03 1015 결과: {'output': '안내해주신 조건에 따라 작동하도록 하겠습니다.\\n\\n- 주어진 json이 없으면 \"2025.05.03 에는 데이터가 없습니다\"를 반환합니다.\\n- 성공 시 success, 실패 시 retry를 반환합니다.\\n- 중복(source) 데이터가 있어도 success만 반환합니다.\\n\\n각 필드 매핑:\\n- fieldValues3_Field_Value: title\\n- fieldValues4_Field_Value: url\\n- fieldValues5_Field_Value: summery\\n- fieldValues6_Field_Value: stock_code\\n\\n뉴스 관련 특이사항도 이해했습니다.\\n\\n이제 등록할 json 데이터를 입력해 주세요.'}\n",
      "수집 중: 2025.05.03 - 뉴스사 1009\n",
      "2025.05.03 1009 결과: {'output': '2025.05.03 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.03 - 뉴스사 1011\n",
      "2025.05.03 1011 결과: {'output': '2025.05.03 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.02 - 뉴스사 1015\n",
      "2025.05.02 1015 결과: {'output': '2025.05.02 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.02 - 뉴스사 1009\n",
      "2025.05.02 1009 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.05.02 - 뉴스사 1011\n",
      "2025.05.02 1011 결과: {'output': '2025.05.02 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.01 - 뉴스사 1015\n",
      "2025.05.01 1015 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.05.01 - 뉴스사 1009\n",
      "2025.05.01 1009 결과: {'output': '2025.05.01 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.05.01 - 뉴스사 1011\n",
      "2025.05.01 1011 결과: {'output': '알겠습니다. 정리하면 아래와 같이 처리하겠습니다.\\n\\n1. json이 주어지지 않으면 \"2025.05.01 에는 데이터가 없습니다\"를 반환합니다.\\n2. json이 온 경우 뉴스 기사에서 상장기업 및 주식코드를 찾을 수 있는 경우에만 Supabase에 저장(입력) 시도합니다.\\n3. 이미 동일한 source(뉴스 URL)가 있더라도 성공(success) 응답만을 반환합니다.\\n4. 없는 경우 삽입 시도 후 성공이면 success, 실패면 retry를 반환합니다.\\n5. 뉴스 중 상장기업 및 주식코드를 찾을 수 없는 뉴스(예시로 든 3개 같은)는 모두 필터링해서 입력하지 않습니다.\\n\\n입력 매핑 규칙:\\n- fieldValues3_Field_Value: title\\n- fieldValues4_Field_Value: url\\n- fieldValues5_Field_Value: summary\\n- fieldValues6_Field_Value: stock_code\\n\\n이 흐름에 따라 주어지는 JSON에 대해 처리하겠습니다. JSON을 입력해 주세요!'}\n",
      "수집 중: 2025.04.30 - 뉴스사 1015\n",
      "2025.04.30 1015 결과: {'output': '2025.04.30 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.30 - 뉴스사 1009\n",
      "2025.04.30 1009 결과: {'output': '네, 이해했습니다. 다음과 같이 정리합니다:\\n\\n- json 데이터가 주어지지 않으면 \"2025.04.30 에는 데이터가 없습니다\"라는 메시지를 반환합니다.\\n- json 데이터가 주어지면, 주어진 스키마에 맞춰 데이터(특히 title, url, summary, stock_code)를 필드에 매핑하여 Supabase에 입력합니다.\\n- 이미 동일한 source(원문 url 또는 고유값)가 존재해도 \"success\"만을 반환합니다.\\n- 상장회사(stock_code) 관련성 판단은 기사 내에 명시적으로 상장 기업명이 나오거나, 확실히 관련됨이 드러나는 기사만 필터링 후 등록합니다.\\n\\n지금은 회사명과 주식 코드가 확실하지 않은 상태입니다.  \\n특정 상장회사명을 명시해 주시면 예시 json 및 처리 예시를 제공해드릴 수 있습니다.  \\n또는 실제로 입력하실 json 데이터를 올려주시면, 규칙에 따라 자동 등록을 시도하겠습니다.  \\n지침은 모두 숙지하였으니, 다음 단계로 json 데이터를 주세요.'}\n",
      "수집 중: 2025.04.30 - 뉴스사 1011\n",
      "2025.04.30 1011 결과: {'output': '알겠습니다. 다음과 같이 처리하면 됩니다.\\n\\n- json 데이터가 주어지지 않으면 \"2025.04.30 에는 데이터가 없습니다\"를 반환합니다.\\n- 데이터 입력(또는 이미 존재해도) 성공 시 \"sucess\", 실패 시 \"retry\"를 반환합니다.\\n- 주어진 스키마에 따라 필드를 매핑합니다.\\n- 입력 시 stock_code가 없거나 찾을 수 없는 경우, 해당 뉴스는 저장하지 않습니다.\\n\\n현재 메시지에선 json이 주어지지 않아서 \"2025.04.30 에는 데이터가 없습니다\"를 반환합니다.\\n\\n추가적인 뉴스 데이터(json)나 기업 주식 코드 정보가 있으시면 제공해 주세요. 입력 처리를 도와드리겠습니다.'}\n",
      "수집 중: 2025.04.29 - 뉴스사 1015\n",
      "2025.04.29 1015 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.04.29 - 뉴스사 1009\n",
      "2025.04.29 1009 결과: {'output': '2025.04.29 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.29 - 뉴스사 1011\n",
      "2025.04.29 1011 결과: {'output': '2025.04.29 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.28 - 뉴스사 1015\n",
      "2025.04.28 1015 결과: {'output': 'success\\n\\n(성공적으로 입력이 처리되었습니다.)'}\n",
      "수집 중: 2025.04.28 - 뉴스사 1009\n",
      "2025.04.28 1009 결과: {'output': 'sucess'}\n",
      "수집 중: 2025.04.28 - 뉴스사 1011\n",
      "2025.04.28 1011 결과: {'output': '2025.04.28 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.27 - 뉴스사 1015\n",
      "2025.04.27 1015 결과: {'output': '\"2025.04.27 에는 데이터가 없습니다\"'}\n",
      "수집 중: 2025.04.27 - 뉴스사 1009\n",
      "2025.04.27 1009 결과: {'output': '2025.04.27 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.27 - 뉴스사 1011\n",
      "2025.04.27 1011 결과: {'output': '2025.04.27 에는 데이터가 없습니다'}\n",
      "수집 중: 2025.04.26 - 뉴스사 1015\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.26 1015 결과: {}\n",
      "수집 중: 2025.04.26 - 뉴스사 1009\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.26 1009 결과: {}\n",
      "수집 중: 2025.04.26 - 뉴스사 1011\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.26 1011 결과: {}\n",
      "수집 중: 2025.04.25 - 뉴스사 1015\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.25 1015 결과: {}\n",
      "수집 중: 2025.04.25 - 뉴스사 1009\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.25 1009 결과: {}\n",
      "수집 중: 2025.04.25 - 뉴스사 1011\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.25 1011 결과: {}\n",
      "수집 중: 2025.04.24 - 뉴스사 1015\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.24 1015 결과: {}\n",
      "수집 중: 2025.04.24 - 뉴스사 1009\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.24 1009 결과: {}\n",
      "수집 중: 2025.04.24 - 뉴스사 1011\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.24 1011 결과: {}\n",
      "수집 중: 2025.04.23 - 뉴스사 1015\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.23 1015 결과: {}\n",
      "수집 중: 2025.04.23 - 뉴스사 1009\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.23 1009 결과: {}\n",
      "수집 중: 2025.04.23 - 뉴스사 1011\n",
      "요청 중 오류가 발생했습니다: Expecting value: line 1 column 1 (char 0)\n",
      "2025.04.23 1011 결과: {}\n",
      "수집 중: 2025.04.22 - 뉴스사 1015\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m retry_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retry_count \u001b[38;5;241m<\u001b[39m max_retries:\n\u001b[1;32m---> 26\u001b[0m     result \u001b[38;5;241m=\u001b[39m fetch_news_from_webhook(\n\u001b[0;32m     27\u001b[0m         query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m     28\u001b[0m         date\u001b[38;5;241m=\u001b[39mdate_str,\n\u001b[0;32m     29\u001b[0m         news_office_checked\u001b[38;5;241m=\u001b[39mnews_office\n\u001b[0;32m     30\u001b[0m     )\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# retry가 있으면 재시도\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretry\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m, in \u001b[0;36mfetch_news_from_webhook\u001b[1;34m(query, date, news_office_checked)\u001b[0m\n\u001b[0;32m     23\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query,\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m: date,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews_office_checked\u001b[39m\u001b[38;5;124m\"\u001b[39m: news_office_checked\n\u001b[0;32m     27\u001b[0m }\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m     31\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# 시작 날짜 설정 (2025.06.30)\n",
    "current_date = datetime(2025, 4, 27)\n",
    "\n",
    "# 검색어와 뉴스사 리스트 설정\n",
    "query = \"사기\"\n",
    "news_offices = [\"1015\", \"1009\", \"1011\"] # 한국경제, 매일경제, 서울경제\n",
    "\n",
    "# 과거로 이동하면서 데이터 수집\n",
    "while current_date.year >= 2025:  # 2025년까지 수집\n",
    "    \n",
    "    # 날짜 형식 변환 (YYYY.MM.DD)\n",
    "    date_str = current_date.strftime(\"%Y.%m.%d\")\n",
    "    \n",
    "    # 각 뉴스사별로 데이터 수집\n",
    "    for news_office in news_offices:\n",
    "        print(f\"수집 중: {date_str} - 뉴스사 {news_office}\")\n",
    "        \n",
    "        # API 호출 및 재시도 로직\n",
    "        max_retries = 3\n",
    "        retry_count = 0\n",
    "        \n",
    "        while retry_count < max_retries:\n",
    "            result = fetch_news_from_webhook(\n",
    "                query=query,\n",
    "                date=date_str,\n",
    "                news_office_checked=news_office\n",
    "            )\n",
    "            \n",
    "            # retry가 있으면 재시도\n",
    "            if result.get('retry'):\n",
    "                print(f\"재시도 {retry_count + 1}/{max_retries}\")\n",
    "                retry_count += 1\n",
    "                time.sleep(2)  # 재시도 전 2초 대기\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        # 결과 출력\n",
    "        print(f\"{date_str} {news_office} 결과: {result}\")\n",
    "        \n",
    "        # API 호출 간 간격 두기 \n",
    "        time.sleep(2)\n",
    "    \n",
    "    # 하루 전으로 이동\n",
    "    current_date -= timedelta(days=1)\n",
    "    \n",
    "print(\"데이터 수집 완료\")\n",
    "# 현재 날짜와 시간을 포함한 로그 파일명 생성\n",
    "log_filename = datetime.now().strftime(\"%Y%m%d_%H%M%S_log.txt\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
